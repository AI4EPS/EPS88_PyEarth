{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drivers of glacial-interglacial cycles\n",
    "\n",
    "We have talked about how 20,000 years ago during the Last Glacial Maximum, much of North America has covered by a thick ice sheet:\n",
    "\n",
    "<img src=\"./images/ice_sheets_2x.png\" width = 600>\n",
    "\n",
    "\n",
    "<img src=\"./images/LGM_Modern_ice.png\" width = 600>\n",
    "\n",
    "We have looked at ice core data that shows that CO$_2$ has varied through time:\n",
    "\n",
    "<img src=\"./images/ice_core_co2.png\" width = 600>\n",
    "\n",
    "**What sets the timing of these glacial-interglacial cycles?**\n",
    "\n",
    "## Earth's orbit - pacemaker of the Ice Ages\n",
    "\n",
    "*material in this section of the notebook is modified from materials of Lisa Tauxe's Python for Earth Science Students course: https://github.com/ltauxe/Python-for-Earth-Science-Students*\n",
    "\n",
    "In 1920, Milutin Milankovitz  explained the coming and going of ice ages as a response to changes in the Earth's _insolation_ (the amount of energy recieved from the sun). He argued that insolation is controlled by changes in the Earth's orbit around the sun.  This idea has now been widely embraced by the paleoclimate community, largely because of the very strong coherence between  cycles in Earth's orbit and evidence for changes in ice volume using geochemical proxies like oxygen isotopes —— data we will look at today.  \n",
    "\n",
    "The orbital cycles are influenced by gravity of the Moon, Sun, Jupiter, and Saturn and can be calculated knowing their orbital parameters.  Milankovitch famously took the first stab at it from his prison cell during WWI. Nowadays it is calculated with supercomputers.  The key parameters: **eccentricity**, **obliquity**, and **precession**.  \n",
    "\n",
    "**Eccentricity** refers to the shape of Earth's orbit around the Sun. It varies between nearly circular (low eccentricity) and more elliptical (high eccentricity) over a period of approximately 100,000 years. Although eccentricity itself does not cause significant changes in the total amount of solar radiation (insolation) received by Earth, it modulates the influence of the other two orbital parameters, obliquity and precession.\n",
    "\n",
    "**Obliquity** is the tilt of Earth's axis relative to its orbital plane. It changes between 22.1° and 24.5° over a period of about 41,000 years. Obliquity has a direct impact on insolation, as it determines the seasonal distribution of solar radiation at different latitudes. Higher obliquity generally leads to more pronounced seasons, with warmer summers and colder winters.\n",
    "\n",
    "**Precession** is the wobble of Earth's axis, which causes the timing of the solstices and equinoxes to change relative to Earth's position in its orbit. It has a period of approximately 19,000 to 23,000 years. Precession affects the seasonal contrast between hemispheres, making one hemisphere's summer more intense while the other hemisphere experiences a milder summer.\n",
    "\n",
    "<img src=\"./images/Milankovitch_Cycles.jpg\" width = 600>\n",
    "\n",
    "[_Figure from_ http://www.jamstec.go.jp/e/about/press_release/20141027/; _see also_ http://www.sciencecourseware.org/eec/GlobalWarming/Tutorials/Milankovitch/].  \n",
    "\n",
    "The Earth's orbital parameters of ellipticity, obliquity and precession vary in predictable ways.  One commonly used model for variations in them over the last few hundred million years was published by Laskar et al. (2004; http://dx.doi.org/10.1051/0004-6361:20041335).  \n",
    "\n",
    "> This solution has been improved...by using a direct integration of the gravitational equations for the orbital motion, and by improving the dissipative contributions, in particular in the evolution of the Earth–Moon System. The orbital solution has been used for the calibration of the Neogene period (Lourens et al.  [CITE]), and is expected to be used for age calibrations of paleoclimatic data over 40 to 50 Myr, eventually over the full Palaeogene period (65 Myr) with caution. Beyond this time span, the chaotic evolution of the orbits prevents a precise determination of the Earth's motion. However, the most regular components of the orbital solution could still be used over a much longer time span. - Laskar et al. (2004)\n",
    "\n",
    "Let's take a look for the behavior of the last few million years using the data file from the Laskar et al. (2004) paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the scientific python packages we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Lasker orbital solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbital_cycles = pd.read_csv('./data/INSOLN.LA2004.BTL.100.csv')\n",
    "orbital_cycles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for you to write**\n",
    "\n",
    "Define a variable called `orbital_cycles_1Myr` that is filtered to only have data for the past 1 million years (1000 ka)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbital_cycles_1Myr = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(orbital_cycles_1Myr['Age (ka)'],orbital_cycles_1Myr['Eccentricity'])\n",
    "plt.ylabel('Eccentricity')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(orbital_cycles_1Myr['Age (ka)'],orbital_cycles_1Myr['Obliquity'])\n",
    "plt.ylabel('Obliquity')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(orbital_cycles_1Myr['Age (ka)'],orbital_cycles_1Myr['Precession'])\n",
    "plt.ylabel('Precession')\n",
    "plt.xlabel('Age (ka)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relating these cycles to incoming insolation\n",
    "\n",
    "You can see a lot of cycles on different time scales. The question is how this relates to the amount of insolation.  In the literature, there are many attempts to convert the orbital parameters, like those in the plot above, to the amount of insolation received by the Earth's atmosphere as a function of latitude and age. You can get such estimates here: https://www.ncdc.noaa.gov/paleo-search/study/5792 associated with this paper (Huybers, P. 2006, http://www.sciencemag.org/cgi/content/full/313/5786/508).  \n",
    "\n",
    "It is traditional to consider the amount of insolation received at 65$^{\\circ}$N.  So let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insolation = pd.read_csv('./data/j_65north.csv')\n",
    "insolation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for you to write**\n",
    "\n",
    "Make a plot using `plt.plot` of the insolation curve. Use `plt.xlim()` to make it so that time is limited and goes from 1000 ka to 0 ka (1,000 thousand years ago [same as 1 million] to present-day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big are these insolation changes?\n",
    "\n",
    "These changes in insolation are interpretted to be important in driving glacial-interglacial cycles. How big are the changes in insolation?\n",
    "\n",
    "**Code for you to write**\n",
    "\n",
    "*Calculate the mean insolation from data (`np.mean()` could help) and the maximum insolation from the data (`np.max()` could help. Then use these values to calculate the percentage difference between the maximum insolation and the mean. Do the same between the maximum and the minimum.* \n",
    "\n",
    "**Does this change seem like a big change sufficient to drive these cycles?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at the ice core CO$_2$ data we have been dealing with. Does the signal match with the insolation signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_core_co2 = pd.read_csv('./data/antarctica2015co2composite.txt',header=137,sep='\\t')\n",
    "ice_core_co2['age_ka'] = ice_core_co2['age_gas_calBP']/1000\n",
    "ice_core_co2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze these data, we need to have an evenly spaced timeseries. We can use the scipy interpolation capabilities to do so. Here is an simple example from the scipy documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "x = np.linspace(0, 10, num=11, endpoint=True)\n",
    "y = np.cos(-x**2/9.0)\n",
    "f = interp1d(x, y)\n",
    "f2 = interp1d(x, y, kind='cubic')\n",
    "\n",
    "xnew = np.linspace(0, 10, num=41, endpoint=True)\n",
    "plt.plot(x, y, 'o')\n",
    "plt.plot(xnew, f(xnew), '-')\n",
    "plt.plot(xnew, f2(xnew), '--')\n",
    "plt.legend(['data', 'linear', 'cubic'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply such an interpolation to the ice core data and resample it a evenly spaced 1 kyr intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_interp = interp1d(ice_core_co2['age_ka'], ice_core_co2['co2_ppm'], kind='linear')\n",
    "\n",
    "xnew = np.linspace(0, 800,num=801,endpoint=True)\n",
    "co2_interp = ice_interp(xnew)\n",
    "plt.plot(ice_core_co2['age_ka'],ice_core_co2['co2_ppm'], 'o')\n",
    "plt.plot(xnew, co2_interp, '-')\n",
    "plt.legend(['data', 'interpolation'], loc='best')\n",
    "plt.xlim(800,0)\n",
    "plt.xlabel('Age (ka)')\n",
    "plt.ylabel('CO$_2$ (ppm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(xnew, co2_interp, '-')\n",
    "plt.xlim(800,0)\n",
    "plt.xlabel('Age (ka)')\n",
    "plt.ylabel('CO$_2$ (ppm)')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(insolation['Age (ka)'],insolation['Insolation (W/m^2)'])\n",
    "plt.xlim(1000,0)\n",
    "plt.ylabel('Insolation (W m$^{-2}$)')\n",
    "plt.xlabel('Age (ka)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral analysis\n",
    "\n",
    "Both insolation and $\\delta ^{18}$O have a lot of wiggles over the last million years, but are the wiggles related to each other?  One way to look at this is using _time series analysis_.   There are entire courses devoted to this subject and a complete treatment is beyond the scope of this class, but we can begin to answer the basic question: *Do the two data sets have wiggles with the same frequencies?*\n",
    "\n",
    "The analysis boils down to this: \n",
    "\n",
    "- According to Fourier, any periodic function $f(t)$ can be represented as the sum of a series of sines and cosines:   \n",
    "\n",
    "$$f(t)=a_0+ \\sum_{r=1}^\\infty \\bigr[a_r    \\cos  \\bigr( { {2\\pi r}\\over{T}}   t\\bigr)  + b_r    \\sin  \\bigr( { {2\\pi r}\\over{T}}   t\\bigl) \\bigl]  $$\n",
    "\n",
    "- You can represent data as a series in time (in the time-domain) as we have been doing OR you can represent the data in terms of frequency, looking for the _power_ in the data as a function of frequency.  This is known as the _power spectrum_. \n",
    "\n",
    "**Phone audio demo**\n",
    "\n",
    "Let us take advantage of a **signal.periodogram** function in the **scipy** package.  That module has functions that allow us to  calculate the _power spectral density_ for a time series.  As a result we will be able to generate a _periodogram_, which is a plot of power versus frequency. \n",
    "\n",
    "We will also use a _window_ in the periodogram calculation.  What a _window_ does is multiply the time series by a function (called a taper) that weights information, suppressing data at the edges of the window and focussing on the center of the window. This step is necessary as otherwise there are artifacts that are introduced particularly given the finite nature of the data (i.e. that the signal starts and ends).  The simplest window is a _box car_ which gives equal weight to everything inside the window.  In the following, we will use a Hann window_ which looks more like a bell curve. The Hann window is a popular choice for general-purpose spectral analysis as it provides a good balance between frequency resolution and spectral leakage reduction. You can check it out here: https://en.wikipedia.org/wiki/Window_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the dominant signal in the ice sheet CO$_2$ data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_freqs,co2_power = signal.periodogram(co2_interp,window='hann')\n",
    "\n",
    "plt.plot(co2_freqs,co2_power,label='CO$_2$ power spectra',linewidth=2)\n",
    "\n",
    "plt.xlim(.001,.1)\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Power') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this dominant peak correspond to?\n",
    "\n",
    "We know that eccentricity is supposed to have a dominant period at 100 kyr, obliquity at 41 kyr and precession at 23 and 19 kyr. Remember that these numbers are expressed in terms of the period, which is the inverse of the frequency so the frequency of them with be the inverse of the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity_frequency = 1.0/100.0\n",
    "obliquity_frequency = 1.0/41.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(co2_freqs,co2_power,label='CO$_2$ power spectra',linewidth=2)\n",
    "plt.axvline(x=eccentricity_frequency,color='red',label='Eccentricity',linewidth=2,linestyle='--') \n",
    "plt.axvline(x=obliquity_frequency,color='orange',label='Obliquity',linewidth=2,linestyle='--') \n",
    "plt.xlim(.001,.06)\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Power') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the dominant periodic signal in the insolation curve?\n",
    "\n",
    "**Code for you to write**\n",
    "\n",
    "Take the same approach above and use the `signal.periodogram()` function to calculate the power spectral density of the 65$^{\\circ}$N insolation curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for you to write**\n",
    "\n",
    "Plot the periodogram and plot the eccentricity and obliquity lines as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the dominant signal in the 65ºN insolation curve and how does it compare to dominant period in the ice sheet CO$_2$ data?\n",
    "\n",
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longer timescale paleoclimate records\n",
    "\n",
    "The ice core record is a very impressive one, but unfortunately, it only goes back ~800,000 years. While these seems like a long time, it is only 0.02% of the history of the Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(800000/4.6e9)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oxygen isotopes\n",
    "\n",
    "One way that we can go further back with a paleoclimate record is using marine fossils such as foraminifera. Foraminifera are made of calcium carbonate: CaCO$_3$\n",
    "\n",
    "The oxygen isotopes ($^{16}$O vs $^{18}$O) in the CaCO$_3$ forms a record of both temperature and ice volume. $\\delta$^{18}$O$ is a way to express the ratio between $^{16}$O and $^{18}$O. \n",
    "\n",
    "$$\\delta ^{{18}}O={\\Biggl (}{\\frac  {{\\bigl (}{\\frac  {^{{18}}O}{^{{16}}O}}{\\bigr )}_{{sample}}}{{\\bigl (}{\\frac  {^{{18}}O}{^{{16}}O}}{\\bigr )}_{{standard}}}}-1{\\Biggr )}\\times 1000\\ ^{{o}}\\!/\\!_{{oo}}$$\n",
    "\n",
    "When water is warm, the $\\delta ^{{18}}O$ of the fossils is low and when water is cold $\\delta ^{{18}}O$ is higher. There is a similar relationship with ice volume: when there is less ice the $\\delta ^{{18}}O$ of water is lower and there is more ice is cold $\\delta ^{{18}}O$ of water is higher which ends up contributing to the value of the fossil foraminifera.\n",
    "\n",
    "So higher $\\delta$^{18}$O$ values are associated with a colder planet and lower $\\delta$^{18}$O$ values with a warmer planet.\n",
    "\n",
    "A compilation of these data was published by Lisecki and Raymo (2005, http://dx.doi.org/10.1029/2004PA001071) called the LR04 stack.  This is a stack of 58 records of oxygen isotopic variations, several of which were independently dated using magnetostratigraphy, from all over the world's oceans.   \n",
    "\n",
    "Let's import the data and take a look at the record: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR04_d18O = pd.read_csv('./data/LR04stack.csv')\n",
    "LR04_d18O.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d18O_1Ma=LR04_d18O[LR04_d18O['Age (ka)']<1000] # filter data for last 1Ma\n",
    "\n",
    "plt.plot(d18O_1Ma['Age (ka)'],d18O_1Ma['d18O'])\n",
    "plt.xlabel('Age (ka)')\n",
    "plt.ylabel('$\\delta ^{18}$O')\n",
    "plt.ylim(5,3)\n",
    "plt.xlim(1000,0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same signal analysis in order to analyze the power spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d18O_freqs,d18O_power = signal.periodogram(d18O_1Ma['d18O'],window='hann')\n",
    "\n",
    "plt.plot(d18O_freqs,d18O_power,label='insolation',linewidth=2)\n",
    "plt.axvline(x=eccentricity_frequency,color='red',label='Eccentricity',linewidth=2,linestyle='--') \n",
    "plt.axvline(x=obliquity_frequency,color='orange',label='Obliquity',linewidth=2,linestyle='--') \n",
    "plt.xlim(.001,.06)\n",
    "\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Power') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "How can we determine that a spectral peak is significant and not just the result of noise in the data?\n",
    "\n",
    "Let's take this approach:\n",
    "\n",
    "1. **Fit an AR1 (Autoregressive order 1) model to the CO2 data (`co2_interp`)**:\n",
    "An AR1 model is a simple time series model that assumes that the value at time t depends linearly on the value at time t-1 and some noise. It is often used to model \"red noise\" or \"autocorrelated noise\" that is common in many natural time series like climate data.\n",
    "\n",
    "2. **Generate synthetic red noise time series**:\n",
    "We generate a large number (`n_synthetic = 1000`) of synthetic time series using the AR1 model parameters estimated from the CO2 data. Each synthetic time series has the same length (n_samples) as the CO2 data. By generating these synthetic time series, we create a set of surrogate data with similar statistical properties to the original CO2 data but without any real-world signal.\n",
    "\n",
    "3. **Compute the power spectra of the synthetic time series**:\n",
    "For each synthetic time series, we calculate the power spectrum using the periodogram method with a Hann window. This gives us an estimate of the power at different frequencies in each synthetic time series. We store these power spectra in a 2D array, synthetic_power_spectra.\n",
    "\n",
    "4. **Calculate the 95th percentile of the synthetic power spectra**:\n",
    "Compute the 95th percentile power spectrum across all the synthetic time series. This spectrum represents the threshold above which we can consider a peak in the CO2 power spectrum as significant (with a 95% confidence level).\n",
    "\n",
    "5. **Compute the periodogram of the CO2 data (`co2_interp`)**:\n",
    "Calculate the power spectrum of the CO2 data using the periodogram method with a Hann window. This gives us an estimate of the power at different frequencies in the CO2 data.\n",
    "\n",
    "6. **Plot the power spectra and the significant peaks**:\n",
    "Plot the power spectra of the CO2 data along with the 95th percentile threshold calculated from the synthetic power spectra. Any peaks in the CO2 power spectrum that rise above the 95th percentile threshold can be considered significant, meaning that they are unlikely to have occurred due to random fluctuations (red noise) alone.\n",
    "\n",
    "Following this approach, we can evaluate our confidence in interpreting the power spectra in the CO2 data. We can identify significant peaks in the power spectrum that are likely to be genuine features of the data rather than artifacts of random fluctuations or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "# Fit an AR1 model to the co2_interp data\n",
    "ar1_model = ARIMA(co2_interp, order=(1, 0, 0)).fit()\n",
    "\n",
    "# Generate a large number of synthetic red noise time series\n",
    "n_synthetic = 1000\n",
    "n_samples = len(co2_interp)\n",
    "phi = ar1_model.params[1]\n",
    "residuals = ar1_model.resid\n",
    "residual_variance = np.var(residuals)\n",
    "white_noise_std = np.sqrt(residual_variance)\n",
    "\n",
    "synthetic_power_spectra = np.zeros((n_synthetic, n_samples // 2))\n",
    "for i in range(n_synthetic):\n",
    "    red_noise = np.zeros(n_samples)\n",
    "    red_noise[0] = np.random.normal(loc=0, scale=white_noise_std)\n",
    "    for t in range(1, n_samples):\n",
    "        red_noise[t] = phi * red_noise[t - 1] + np.random.normal(loc=0, scale=white_noise_std)\n",
    "    \n",
    "    red_noise_freqs, synthetic_power_spectrum = periodogram(red_noise, window='hann')\n",
    "    synthetic_power_spectra[i, :] = synthetic_power_spectrum[:n_samples // 2]\n",
    "\n",
    "# Compute the 95th percentile of the synthetic power spectra\n",
    "threshold_power_spectrum = np.percentile(synthetic_power_spectra, 95, axis=0)\n",
    "\n",
    "# Compute the periodogram for co2_interp data\n",
    "co2_freqs, co2_power = periodogram(co2_interp, window='hann')\n",
    "\n",
    "# Make sure the lengths of co2_freqs and threshold_power_spectrum are the same\n",
    "co2_freqs = co2_freqs[:len(threshold_power_spectrum)]\n",
    "\n",
    "# Plot the power spectra and the significant peaks\n",
    "plt.plot(co2_freqs, co2_power[:len(threshold_power_spectrum)], label='CO$_2$ power spectra', linewidth=2)\n",
    "plt.plot(co2_freqs, threshold_power_spectrum, label='95% confidence level', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlim(.001, .1)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Power')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
