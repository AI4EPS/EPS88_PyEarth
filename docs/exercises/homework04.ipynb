{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Earthquakes and Plate Tectonics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import cm\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io.shapereader import Reader\n",
    "from geopy import distance\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Plate Tectonics\n",
    "\n",
    "### 1.1 Topography\n",
    "\n",
    "Let us use the `Orthographic` projection (A GLOBE! in the XKCD map projection cartoon) to look at the large underwater mountain range of the Mid-Atlantic ridge.\n",
    "\n",
    "The `plt.contourf` function is slow such that we will need to have some patience when running the plotting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the topography data using np.loadtxt\n",
    "lats = np.loadtxt(       # ./data/etopo20lats.txt\n",
    "lons = np.loadtxt(       # ./data/etopo20lons.txt\n",
    "topo_grid = np.loadtxt(  # ./data/etopo20data.txt\n",
    "\n",
    "## Create a meshgrid for latitude and longitude using np.meshgrid\n",
    "lon_grid, lat_grid = np.meshgrid(\n",
    "\n",
    "## Check the shape of lat_grid, lon_grid, and topo_grid are the same\n",
    "print(f\"Shape of lat_grid: {lat_grid.shape}, Shape of lon_grid: {lon_grid.shape}, Shape of topo_grid: {topo_grid.shape}\")\n",
    "\n",
    "## Downsample the data to make the plotting faster\n",
    "lon_grid = lon_grid[::2, ::2]\n",
    "lat_grid = lat_grid[::2, ::2]\n",
    "topo_grid = topo_grid[::2, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the topography using the Orthographic projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Set the projection\n",
    "ax = plt.axes(projection=ccrs.Orthographic(central_longitude=-40.0, central_latitude=20.0))\n",
    "ax.set_global()\n",
    "\n",
    "## Plot the topography using the Orthographic projection\n",
    "plt.contourf(\n",
    "\n",
    "## Add coastlines and gridlines\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "## Add colorbar\n",
    "color_ax = plt.axes([0.95, 0.3, 0.05, 0.35])\n",
    "plt.colorbar(cax=color_ax, label='elevation/depth (m)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Seafloor age\n",
    "\n",
    "Plot seafloor age looking at North Atlantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the seafloor age data\n",
    "seafloor_age_data = pd.read_csv(      # data/age.csv\n",
    "\n",
    "## extract longitude, latitude, and age\n",
    "age_longitude = seafloor_age_data['\n",
    "age_latitude = seafloor_age_data['\n",
    "age = seafloor_age_data['\n",
    "\n",
    "## reshape the data to 2D arrays. Hint: the shape of the data is (901,1801)\n",
    "age_grid = age.reshape((901,1801))\n",
    "age_long_grid = age_longitude.reshape((901,1801))\n",
    "age_lat_grid = age_latitude.reshape((901,1801))\n",
    "\n",
    "## check the shape of the data\n",
    "print(f\"Shape of age_grid: {age_grid.shape}, Shape of age_long_grid: {age_long_grid.shape}, Shape of age_lat_grid: {age_lat_grid.shape}\")\n",
    "\n",
    "## Downsample the data to make the plotting faster\n",
    "age_long_grid = age_long_grid[::4, ::4]\n",
    "age_lat_grid = age_lat_grid[::4, ::4]\n",
    "age_grid = age_grid[::4, ::4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the seafloor age using the Orthographic projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Set the projection\n",
    "ax = plt.axes(projection=ccrs.Orthographic(central_longitude=-40.0, central_latitude=20.0))\n",
    "ax.set_global()\n",
    "\n",
    "## Plot the seafloor age using the Orthographic projection\n",
    "plt.contourf(\n",
    "\n",
    "## Add coastlines and gridlines\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "## Add colorbar\n",
    "color_ax = plt.axes([0.95, 0.3, 0.05, 0.35])\n",
    "plt.colorbar(cax=color_ax, label='Age, Myr') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What patterns do you observe? Where is the youngest seafloor in relation to the seafloor ridges we observed in our map of topography? Where is the oldest seafloor? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the position of the continents like when the oldest seafloor formed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Earthquake Catalog\n",
    "\n",
    "Based on the seafloor age data, we know that the tectonic plates are moving away from the ridges and towards the trenches.\n",
    "\n",
    "The movement of the plates will compress and stretch the plates. The accumulated stress will eventually be too much and the plates will break, causing an earthquake.\n",
    "\n",
    "Large earthquakes are often associated with plate boundaries. Let's continue to explore the earthquake data to see if we can find any patterns.\n",
    "\n",
    "\n",
    "- 2022's tragic earthquake in Turkey\n",
    "\n",
    "https://earthquake.usgs.gov/earthquakes/eventpage/us6000jllz/executive\n",
    "\n",
    "https://earthquake.usgs.gov/earthquakes/map/?currentFeatureId=us6000jllz&extent=-26.11599,-43.59375&extent=61.39672,100.89844&sort=largest&listOnlyShown=true\n",
    "\n",
    "<img src=\"images/new-maps-of-global-geo.jpg\" width=50%>\n",
    "> Source: Hasterok et al., 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the Earthquake Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the .csv (comma separated values) data file of all the earthquakes of magnitude 4 and higher from 2000 - 2012 in the ANSS (Advanced National Seismic System) Comprehensive Catalog or \"ComCat.\"\n",
    "\n",
    "The ANSS Comprehensive Catalog (ComCat) http://www.quake.geo.berkeley.edu/anss/catalog-search.html\n",
    "\n",
    "This data set has the following columns:\n",
    "\n",
    "```DateTime, Latitude, Longitude, Depth, Magnitude, MagType, NbStations, Gap, Distance, RMS, Source, EventID```\n",
    "\n",
    "Let's import it using the pandas `pd.read_csv()` function. We can see the first 5 rows of the dataframe using the `.head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the earthquake data. Hint: skipping the first 7 rows using header=7\n",
    "EQ_data = pd.read_csv(   #data/ANSS_2000_2012.csv\n",
    "\n",
    "## Check the first rows of the dataframe\n",
    "EQ_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the homework that Pandas dataframe columns can be accessed using bracket notation with the name of the column as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access the Magnitude column\n",
    "EQ_data['"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the largest magnitude earthquake in our catalog?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the largest magnitude earthquake in our catalog\n",
    "largest_magnitude = \n",
    "\n",
    "print(f\"The largest magnitude earthquake in our catalog is {largest_magnitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determining when and where the largest Earthquake happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the date of the largest earthquake. Hint: using the `==` operator, e.g. EQ_data['DateTime'][EQ_data['Magnitude'] == largest_magnitude], to filter the dataframe, and `.values[0]` to get the first value of the filtered dataframe\n",
    "largest_eq_date = EQ_data['DateTime'][\n",
    "\n",
    "print(f\"The largest earthquake in our catalog happened on {largest_eq_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determine where the earthquake happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the longitude and latitude of the largest earthquake. \n",
    "largest_eq_lon = EQ_data['Longitude'][\n",
    "largest_eq_lat = EQ_data['Latitude'][\n",
    "\n",
    "print(f\"The largest earthquake in our catalog happened at {largest_eq_lon} longitude and {largest_eq_lat} latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many colormaps available in Matplotlib: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "\n",
    "<img src=\"https://matplotlib.org/stable/_images/sphx_glr_colormaps_007_2_00x.png\" width=30%>\n",
    "\n",
    "There are many different markers available in Matplotlib\n",
    "\n",
    "<img src=\"https://matplotlib.org/stable/_images/sphx_glr_marker_reference_002_2_00x.png\" width=30%>\n",
    "\n",
    "Let's plot a red square at the location of the largest earthquake in our catalog. \n",
    "\n",
    "To the `plt.scatter` function, add `s=100` to adjust the size of the marker, add `color='red'` to change the color, add `marker=s` to make it a square. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Set the projection using ccrs.Robinson(central_longitude=180)\n",
    "ax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\n",
    "ax.set_global()\n",
    "\n",
    "## Plot the largest earthquake, using s=100, marker='s', color='red'\n",
    "plt.scatter(\n",
    "\n",
    "## Add coastlines, stock image, and gridlines\n",
    "ax.coastlines()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "## Add a title\n",
    "plt.title('2011 Tōhoku earthquake')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Watch the following video and comment on the effects of this earthquake:\n",
    "\n",
    "https://www.youtube.com/watch?v=oWzdgBNfhQU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Earthquake magnitude distribution\n",
    "\n",
    "How often do large earthquakes occur? To start addressing this question, let's plot a histogram of earthquake magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Plot a histogram of earthquake magnitudes, using bins=30, edgecolor='white'\n",
    "plt.hist(\n",
    "\n",
    "## Label the axes and add a title\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "plt.title('Histogram of Earthquake Magnitudes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many small earthquakes that we can't even see a bin for the Tohoku quake. \n",
    "\n",
    "Let's make the histogram on a log-scale. \n",
    "\n",
    "For any function, we can put a question mark after it to get its docstring. Let's do this for `plt.hist()`. \n",
    "\n",
    "Once you execute the cell below, you will see that there are a lot of options (which you can also view here: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html). \n",
    "\n",
    "One of the options is to make the plot be on a log scale by setting `log=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?plt.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a histogram of the Earthquake magnitude data on a log-scale\n",
    "\n",
    "Set `log=True` within the `plt.hist` function.\n",
    "\n",
    "Let's make sure that this figure has labeled axes using `plt.xlabel()` and `plt.ylabel()` and we can add a title as well using `plt.title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Plot a histogram of earthquake magnitudes, using bins=30, edgecolor='white', log=True\n",
    "plt.hist(\n",
    "\n",
    "## Label the axes and add a title\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "plt.title('Histogram of Earthquake Magnitudes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Earthquake depth\n",
    "\n",
    "Let's see the range and frequency of depths where earthquakes occur. \n",
    "\n",
    "Make a histogram of earthquake depth. Remember to set `log=True` within the `plt.hist` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Plot a histogram of earthquake depths, using bins=30, edgecolor='white', log=True\n",
    "plt.hist(\n",
    "\n",
    "## Label the axes and add a title\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "plt.title('Histogram of Earthquake Depths')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questsion: At what depth are the majority of earthquakes? How deep do they extend? How does that compare to the typical depth of the lithosphere (~100 km)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map we made above is nice, but it doesn't tell us everything about our data. Let's create a map of the earthquake epicenters that colors the points by depth.\n",
    "\n",
    "To do this, use the same `plt.scatter()` function, but add the option to set the color by depth. You can do this by having  `c=EQ_data['Depth']` within the function. \n",
    "\n",
    "You can customize the output by setting the minimum value for the color bar `vmin=0` and the maximum value `vmax=200`. \n",
    "\n",
    "You can also customize the colormap. A perceptually uniform sequential color map like `cmap='magma_r'` works well (https://matplotlib.org/tutorials/colors/colormaps.html). \n",
    "\n",
    "It is also nice to make the points partially see through by setting `alpha=0.5`. \n",
    "\n",
    "All of these customizations can be made by adding these arguments within the `plt.scatter()` function.\n",
    "\n",
    "Make a map that colors points by depth by inserting these arguments in the `plt.scatter()` function in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "## Set the projection using ccrs.Robinson(central_longitude=180)\n",
    "ax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\n",
    "ax.set_global()\n",
    "\n",
    "## Plot the epicenters of the earthquakes, using c=EQ_data['Depth'], s=10, vmin=0,vmax=200,cmap='magma_r',alpha=0.5\n",
    "plt.scatter(\n",
    "\n",
    "## Add coastlines, stock image, and gridlines\n",
    "ax.coastlines()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "## Add a colorbar\n",
    "plt.colorbar(shrink=0.4, label='depth (km)')\n",
    "\n",
    "## Add a title\n",
    "plt.title('Earthquake Epicenters 2000-2012')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What depth of earthquakes occur at mid-ocean ridges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What depth of earthquakes occur at trenches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/slab_eq.png\" width=50%>\n",
    "\n",
    "> Source: Fundamentals of Geophysics (2nd Edition) Lowrie, W.\n",
    "\n",
    "<img src=\"images/slab_eq2.png\" width=50%>\n",
    "\n",
    "> A cross-section through a subduction zone. Red points are earthquake focus points. The most active region is the zone of contact between the plates. There is a back-arc seismic zone in the overriding plate. Below ~70 km depth earthquakes occur within the subducting plate, this region is call the Wadati-Benioff seismic zone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earthquakes at trenches (like around the Pacific ocean's 'ring of fire') get deeper in a systematic way. The deepest earthquakes are the farthest from the trench. This reveals the location of the downgoing slabs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Andean subduction zone\n",
    "\n",
    "Let's look at a subset of this earthquake catalog across the Andes in South America. The code below is filtering the data frame to only include those between 20ºS and 25ºS latitude and 75ºW and 60ºW longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter the data frame to only include those between 20ºS and 25ºS latitude and 75ºW and 60ºW longitude\n",
    "min_lat = -25\n",
    "max_lat = -20\n",
    "min_lon = -75\n",
    "max_lon = -60 \n",
    "selected_quakes = EQ_data["
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a map of the epicenters of these earthquakes following the same procedure as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Set the projection using ccrs.Robinson(central_longitude=180)\n",
    "ax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\n",
    "ax.set_global()\n",
    "\n",
    "## Plot the epicenters of the earthquakes, using s=10, marker='.', color='red'\n",
    "plt.scatter(\n",
    "\n",
    "## Add coastlines, stock image, and gridlines\n",
    "ax.coastlines()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "## Add a title\n",
    "plt.title('Selected Earthquake Epicenters 2000-2012')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take all of the earthquakes within that region and plot earthquake depth on the y-axis and earthquake location on the x-axis. \n",
    "\n",
    "Labeling axes is super important in science! Don't make plots without labeled axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Plot the epicenters of the earthquakes, using longitude on the x-axis and depth on the y-axis, using s=10, marker='.'. \n",
    "## Hint: Using -selected_quakes['Depth'] to plot deeper earthquakes lower on the y-axis\n",
    "plt.scatter(\n",
    "\n",
    "## Label the axes and add a title\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "plt.title('Earthquake depths from 20°S to 25°S')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Japan subduction\n",
    "\n",
    "Let's look at the subduction zone off the east coast of Japan. \n",
    "\n",
    "Please find the correct latitude and longitude range for this region and plot the earthquakes on a map and make a similar depth vs. longitude plot (or depth vs latitude plot) for another region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latitude and longitude range\n",
    "min_lat = 32\n",
    "max_lat = 43\n",
    "min_lon = 135\n",
    "max_lon = 145\n",
    "\n",
    "selected_quakes = EQ_data["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure()\n",
    "\n",
    "## Plot the epicenters of the earthquakes, using longitude on the x-axis and depth on the y-axis, using s=10, marker='.'. \n",
    "## Hint: Using -selected_quakes['Depth'] to plot deeper earthquakes lower on the y-axis\n",
    "plt.scatter(\n",
    "\n",
    "## Label the axes and add a title\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "plt.title('earthquake depths from 30°N to 40°N')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What direction is subduction occuring below South America and Japan? Are they towards the east or west?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Relationship between earthquake location and plate boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stead of using the prepared earthquake catalog, let's use the USGS API to import a global earthquake catalog (Magnitude >= 6.0).\n",
    "\n",
    "This can be very useful if you want to get the latest earthquake data.\n",
    "\n",
    "- Load the earthquake data from the USGS API\n",
    "\n",
    "Update the start_day and end_day (from 2010-01-01 to 2025-01-01) to get a query url that will return earthquakes that occured over the past 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the start and end day from 2010-01-01 to 2025-01-01 and the minimum magnitude = 6.0\n",
    "start_day = '\n",
    "end_day = '\n",
    "min_magnitude = \n",
    "\n",
    "## Define the standard url\n",
    "standard_url = 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&orderby=magnitude'\n",
    "\n",
    "## Define the query url\n",
    "query_url = f\"{standard_url}&starttime={start_day}&endtime={end_day}&minmagnitude={min_magnitude}\"\n",
    "\n",
    "## Read the data from the query url into a dataframe\n",
    "earthquake_data = pd.read_csv(query_url)\n",
    "\n",
    "## Print the first rows of the dataframe\n",
    "earthquake_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotting the plate boundaries and earthquake locations together\n",
    "\n",
    "In addition to plotting the earthquake locations, we can plot the location of plate boundaries. \n",
    "\n",
    "I took the plate boundaries provided by the US Geological Survey (USGS) and split them by their categorization into trenches (subduction zones), ridges (spreading centers) and transform (strike-slip boundaries like the San Andreas fault).\n",
    "\n",
    "The code below makes a map where these different plate boundaries are represented by different color lines. Please add the earthquake locations to this map as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "## Set the projection using ccrs.Robinson(central_longitude=180)\n",
    "ax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\n",
    "ax.set_global()\n",
    "\n",
    "## Add coastlines, stock image, and gridlines\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "## Read the data from the shapefile\n",
    "data = Reader('./data/Plate_Boundaries_transform.shp')\n",
    "\n",
    "## Add the transform plate boundaries to the map\n",
    "ax.add_geometries(data.geometries(), crs=ccrs.PlateCarree(), \n",
    "                  edgecolor='orange', facecolor='none',\n",
    "                  linewidth=3)\n",
    "\n",
    "## Read the data from the shapefile\n",
    "data = Reader('./data/Plate_Boundaries_trenches.shp')\n",
    "\n",
    "## Add the trench plate boundaries to the map\n",
    "ax.add_geometries(data.geometries(), crs=ccrs.PlateCarree(), \n",
    "                  edgecolor='darkblue', facecolor='none',\n",
    "                  linewidth=3)\n",
    "\n",
    "## Read the data from the shapefile\n",
    "data = Reader('./data/Plate_Boundaries_ridges.shp')\n",
    "\n",
    "## Add the ridge plate boundaries to the map\n",
    "ax.add_geometries(data.geometries(), crs=ccrs.PlateCarree(), \n",
    "                  edgecolor='red', facecolor='none',\n",
    "                  linewidth=3)\n",
    "\n",
    "## Make patches to add to a legend\n",
    "trans = mpatches.Rectangle((0, 0), 1, 1, facecolor=\"orange\")\n",
    "con = mpatches.Rectangle((0, 0), 1, 1, facecolor=\"darkblue\")\n",
    "div = mpatches.Rectangle((0, 0), 1, 1, facecolor=\"red\")\n",
    "labels = ['Transform','Convergent','Divergent']\n",
    "plt.legend([trans, con, div], labels)\n",
    "\n",
    "## Add a title\n",
    "plt.title('Map of plate boundaries (red=ridge; blue=trench; orange=transform)')\n",
    "\n",
    "## Plot the earthquake locations on the map. Adjust the color and size of the points as need to make it look nice.\n",
    "plt.scatter(\n",
    "\n",
    "plt.colorbar(shrink=0.4, label='depth (km)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Where do the majority of earthquakes occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What do those locations correspond with? Trenches, ridges, or transform boundaries?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze an Earthquake Seismogram\n",
    "\n",
    "An interesting earthquake in 2020 occured 100km SSE of Perryville, Alaska at 55.0683°N 158.5543°W and was a magnitude 7.8 event.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/zhuwq0/images/main/T5sX3oGmJpkLtVxmUzSWyM-998-80.jpg.webp\" width=30%>\n",
    "\n",
    "You can find more information about this earthquake on the USGS website: https://earthquake.usgs.gov/earthquakes/eventpage/us7000asvb/executive\n",
    "\n",
    "Below is a map of the earthquake location and the location of the Columbia College, Columbia, CA, USA seismic station that recorded a seismograph we will be analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the earthquake location of the 2020 Alaska earthquake\n",
    "Earthquake_lat = 55.0683\n",
    "Earthquake_lon = -158.5543\n",
    "\n",
    "# Define the station location at Columbia College, Columbia, CA, USA\n",
    "station_lat = 38.03455\n",
    "station_lon = -120.38651\n",
    "\n",
    "## Make a figure\n",
    "plt.figure(1,(10,10))\n",
    "\n",
    "## Set the projection using ccrs.Orthographic(central_longitude=-130,central_latitude=60)\n",
    "ax = plt.axes(projection=ccrs.Orthographic(central_longitude=-130,central_latitude=60))\n",
    "ax.set_global()\n",
    "\n",
    "## Read the data from the shapefile\n",
    "data = Reader('./data/Plate_Boundaries_transform.shp')\n",
    "\n",
    "## Add the transform plate boundaries to the map\n",
    "ax.add_geometries(data.geometries(), crs=ccrs.PlateCarree(), \n",
    "                  edgecolor='orange', facecolor='none',\n",
    "                  linewidth=3)\n",
    "\n",
    "## Read the data from the shapefile\n",
    "data = Reader('./data/Plate_Boundaries_trenches.shp')\n",
    "\n",
    "## Add the trench plate boundaries to the map\n",
    "ax.add_geometries(data.geometries(), crs=ccrs.PlateCarree(), \n",
    "                  edgecolor='darkblue', facecolor='none',\n",
    "                  linewidth=3)\n",
    "\n",
    "## Read the data from the shapefile\n",
    "data = Reader('./data/Plate_Boundaries_ridges.shp')\n",
    "\n",
    "## Add the ridge plate boundaries to the map\n",
    "ax.add_geometries(data.geometries(), crs=ccrs.PlateCarree(), \n",
    "                  edgecolor='red', facecolor='none',\n",
    "                  linewidth=3)\n",
    "\n",
    "## Plot the earthquake location on the map\n",
    "plt.scatter(Earthquake_lon,Earthquake_lat,s=100,marker='*',\n",
    "            color='red', edgecolor='black',transform=ccrs.PlateCarree())\n",
    "\n",
    "## Add a text annotation for the earthquake location\n",
    "plt.text(Earthquake_lon+5,Earthquake_lat,'Earthquake',fontsize=14,color='red',\n",
    "         transform=ccrs.PlateCarree())\n",
    "\n",
    "## Plot the seismic station location on the map\n",
    "plt.scatter(station_lon,station_lat,s=100,marker='^',\n",
    "            color='green', edgecolor='black',transform=ccrs.PlateCarree())\n",
    "\n",
    "## Add a text annotation for the seismic station location\n",
    "plt.text(station_lon+5,station_lat,'Columbia College',fontsize=12,color='green',\n",
    "         transform=ccrs.PlateCarree())\n",
    "\n",
    "## Plot the line connecting the earthquake and the seismic station\n",
    "plt.plot([Earthquake_lon,station_lon],[Earthquake_lat,station_lat],\n",
    "         color='red',transform=ccrs.Geodetic())\n",
    "\n",
    "## Add coastlines, stock image, and gridlines\n",
    "ax.coastlines()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "\n",
    "## Add a title\n",
    "plt.title('The 2020 Alaska Earthquake and the Columbia College Seismic Station')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: At what type of plate boundary did this earthquake occur?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More geologic context about this quake can be found here: https://www.iris.edu/hq/files/programs/education_and_outreach/retm/tm_200722_alaska/200722_Alaska.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Distance between seismograph and earthquake\n",
    "\n",
    "We can use the Geopy Python package to calculate the distance between the earthquake and the seismic station. \n",
    "\n",
    "The module `distance` of the `geopy` library was  imported at the beginning of this notebook. \n",
    "\n",
    "You can use `distance.distance(location1, location2)` function where each location is (latitude,longitude).\n",
    "\n",
    "You can read more about this function here: https://geopy.readthedocs.io/en/stable/index.html?highlight=distance#module-geopy.distance\n",
    "\n",
    "In the code cell below, define the locations, use the `distance.distance()` function to calculate the distance, and then assign the value (in km) to a variable called `earthquake_seismograph_distance_km`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the seismic station location (latitude, longitude)\n",
    "seismic_station_location = (\n",
    "\n",
    "## define the earthquake location (latitude, longitude)\n",
    "earthquake_location = (\n",
    "\n",
    "## calculate the distance between the earthquake and the seismic station. Hint: using distance.distance(location1, location2).km\n",
    "earthquake_seismograph_distance_km = distance.distance(\n",
    "\n",
    "print(f'The distance between the earthquake and the seismic station is {earthquake_seismograph_distance_km:.2f} km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load a Seismogram of this Earthquake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the .csv (Comma Separated Variable) data file of this seismogram as recorded at the Columbia College, Columbia, CA, USA seismic station. \n",
    "\n",
    "Samples were taken every 0.025 seconds (40 Hz) and the record starts 60 seconds before the arrival of the first wave which is called the P wave. \n",
    "\n",
    "https://www.iris.edu/app/station_monitor/#2020-07-22T06:12:44/BK-CMB/webicorder/BK-CMB%7C11273635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the seismogram data. Hint: add header=9, names=['Time','Sample'] to the function\n",
    "seismogram = pd.read_csv(   # ./data/BK.CMB.00.BHZ.Q.2020-07-22T061756.019538.csv\n",
    "\n",
    "## Preview format of the seismogram data\n",
    "seismogram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the seismogram data.\n",
    "\n",
    "The `seismogram['Time']` column is a time series of the time of the samples. We need to convert this to a datetime object using `pd.to_datetime()`.\n",
    "\n",
    "The `seismogram['Sample']` column is a time series of the velocity of the ground motion at the location of the seismic station due to this earthquake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract time from seismogram dataframe and assign to time variable. \n",
    "time = \n",
    "\n",
    "## Use pd.to_datetime() to convert the time series to a datetime object\n",
    "time = pd.to_datetime(\n",
    "\n",
    "## Earthquake origin time from USGS: https://earthquake.usgs.gov/earthquakes/eventpage/us7000asvb/executive\n",
    "earthquake_origin_time = pd.to_datetime(\"2020-07-22T06:12.44Z\")\n",
    "\n",
    "## Calculate the travel time in minutes\n",
    "traveltime = (time - earthquake_origin_time).dt.total_seconds() / 60\n",
    "\n",
    "## Extract velocity from seismogram dataframe and assign to velocity variable\n",
    "velocity = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the seismogram with `time` on the x-axis and `velocity` on the y-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Make a figure with a size of 10x5\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "## Plot the seismogram between the travel time and velocity\n",
    "plt.plot(\n",
    "\n",
    "## Add x-axis label and y-axis label\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "\n",
    "## Add a title\n",
    "plt.title('Seismogram of 2020-07-22 Alaskan earthquake recorded at Columbia College, CA')\n",
    "\n",
    "## Add gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seismographs record the arrival of multiple types of waves. P (primary) waves are compressional waves that arrive first. S (secondary/shear) waves are shear waves that arrive next as illustrated in the example seismograph below. \n",
    "\n",
    "Following the P and S waves are the high amplitude surface waves:\n",
    "\n",
    "# <img src=\"images/seis_wave_travel_time.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see from the P and S wave arrival times on the seismograph, if we can determine the distance to the earthquake.\n",
    "\n",
    "To do this, we need to pick the arrival time of the S wave. From the seismograph, read the travel time of the P and S waves.\n",
    "\n",
    "Assign the travel time of the P wave to a variable called `p_wave_travel_time` and the travel time of the S wave to a variable called `s_wave_travel_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wave_travel_time =  #minutes                         \n",
    "s_wave_travel_time =  #minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the seismograph with annotations for the P and S wave arrivals to see if your picks are correct.\n",
    "\n",
    "Using the annotations, we can indicate when the P wave arrived and when the S wave arrived on the seismograph. Take your code from above that plots the seismograph and add this code to also plot annotations:\n",
    "\n",
    "```\n",
    "ax.annotate('P wave', (mdates.date2num(time[psamp]), velocity[psamp]), xytext=(-10, 35), \n",
    "            textcoords='offset points', arrowprops=dict(arrowstyle='-|>'))\n",
    "ax.annotate('S wave', (mdates.date2num(time[ssamp]), velocity[ssamp]), xytext=(-10, 35), \n",
    "            textcoords='offset points', arrowprops=dict(arrowstyle='-|>'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure with a size of 10x5\n",
    "plt.figure(figsize=(10,5))\n",
    "## Plot the seismograph\n",
    "plt.plot(\n",
    "\n",
    "## Plot the P wave annotation\n",
    "plt.annotate('P wave', (p_wave_travel_time, 0), xytext=(-10, 35), \n",
    "            textcoords='offset points', arrowprops=dict(arrowstyle='-|>'))\n",
    "\n",
    "## Plot the S wave annotation\n",
    "plt.annotate('S wave', (s_wave_travel_time, 0), xytext=(-10, 35), \n",
    "            textcoords='offset points', arrowprops=dict(arrowstyle='-|>'))\n",
    "\n",
    "## Add x-axis label and y-axis label\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "\n",
    "## Add a title\n",
    "plt.title('Seismogram of 2020-07-22 Alaskan earthquake recorded at Columbia College, CA')\n",
    "\n",
    "## Add gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your picks are not correct, go back up and adjust the P and S wave arrival times until you are happy with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have made this plot, go back up and adjust the S wave arrival time (which is with respect to the start of the record in fractional minutes). Keep adjusting that value and moving you S wave arrival pick until it as at a spot in the record that you feel happy with. You should be looking for when the record transitions from the amplitude charecteristic of the P wave to a higher amplitude (but an amplitude that is still significantly less than that associated with the surface waves). Look at the example above for guidance.\n",
    "\n",
    "**Keep adjusting and rerunning the code until you are happy with the S wave pick**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your s wave pick subtract the `p_wave_travel_time` from the `s_wave_travel_time` and assign that difference to a variable ```seismogram_s_p_difference``` in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the S-P time difference using the variables p_wave_travel_time and s_wave_travel_time\n",
    "seismogram_s_p_difference = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimate distance based on S-P time difference\n",
    "\n",
    "The difference in P and S wave arrival times can be used to determine the distance from the recording station to the earthquake using a travel time curve if we know the velocities of the waves through the Earth.  So first we need to know how these two waves behave — particularly their velocities. Check out this short video demonstration:\n",
    "\n",
    "https://www.iris.edu/hq/inclass/uploads/videos/A_6_seismictraveltimeirisbounc.mp4\n",
    "\n",
    "https://www.iris.edu/hq/inclass/animation/traveltime_curves_how_they_are_created\n",
    "\n",
    "Calculated travel times based on a standard earth models are in the the data folder as `arrival_times.csv`. The time unit is minutes. Let's import them as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the travel time table\n",
    "travel_time_table = pd.read_csv('./data/arrival_times.csv')\n",
    "\n",
    "## Preview the travel time table\n",
    "travel_time_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the S-P time difference to estimate the distance between the earthquake and the seismograph. \n",
    "\n",
    "So let's create a new column in the travel time table that is the S-P time difference. We want distance in km, so we need to convert the degrees to km.\n",
    "\n",
    "To convert the degrees to km, we need to know the radius of the Earth. The radius of the Earth is 6371 km.\n",
    "\n",
    "The circumference of the Earth is $2\\pi r$ for 360 degrees, so 1 degree is $2\\pi r / 360$ km.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column in the travel time table that is the S-P time difference\n",
    "travel_time_table['S-P_difference'] = \n",
    "\n",
    "## Convert the degrees to km\n",
    "radius_earth = 6371\n",
    "degrees_to_km = 2 * np.pi * radius_earth / 360\n",
    "travel_time_table['distance_km'] = travel_time_table['degrees_from_quake'] * degrees_to_km\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the S-P time difference vs distance in km from the earthquake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "## Plot the S-P time difference vs distance\n",
    "plt.plot(\n",
    "\n",
    "## Add x-axis label and y-axis label\n",
    "plt.ylabel('\n",
    "plt.xlabel('\n",
    "\n",
    "## Add legend and grid\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the timetable between S-P time difference and distance, we can build a linear relationship between the two. \n",
    "\n",
    "The model will take the S-P time difference as input and return the distance as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the input and output variables. Hint: use the `[[]]` to extract S-P time difference as a column. And add `.values` to convert to a numpy array\n",
    "X = travel_time_table[['S-P_difference']].values\n",
    "y = travel_time_table[['distance_km']].values\n",
    "\n",
    "## Fit a linear model using LinearRegression() from sklearn\n",
    "model = \n",
    "model.fit(\n",
    "\n",
    "## Get prediction from the model\n",
    "y_pred = \n",
    "\n",
    "## Evaluate the model using the r2_score function\n",
    "R_squared = \n",
    "print(f'The model R-squared is {R_squared:.2f}')\n",
    "\n",
    "## Plot the prediction\n",
    "plt.figure()\n",
    "plt.scatter(X, y, label='Data')\n",
    "plt.plot(X, y_pred, color='red', label='Linear Regression')\n",
    "plt.xlabel('S-P time difference (minutes)')\n",
    "plt.ylabel('Distance (km)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Is the linear relationship between the S-P time difference and distance fit the data well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can add higher order terms to the model to improve the fit. \n",
    "\n",
    "Recall the `PolynomialFeatures` function from sklearn, which we used in the linear regression lecture.\n",
    "\n",
    "We can use the `make_pipeline` function to add the polynomial features to the model, as we did in the logistic regression/classification lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the input and output variables. Hint: use the `[[]]` to extract S-P time difference as a column\n",
    "X = travel_time_table[['S-P_difference']].values\n",
    "y = travel_time_table[['distance_km']].values\n",
    "\n",
    "\n",
    "## Fit a linear model using make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "model = make_pipeline(\n",
    "model.fit(\n",
    "\n",
    "## Get prediction from the model\n",
    "y_pred = \n",
    "\n",
    "## Evaluate the model using r2_score\n",
    "R_squared = \n",
    "print(f'The model R-squared is {R_squared:.2f}')\n",
    "\n",
    "## Plot the prediction\n",
    "plt.figure()\n",
    "plt.scatter(X, y, label='Data')\n",
    "plt.plot(X, y_pred, color='red', label='Polynomial Regression')\n",
    "plt.xlabel('S-P time difference (minutes)')\n",
    "plt.ylabel('Distance (km)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the polynomial model fits the data better than the linear model, resulting in a higher R-squared value.\n",
    "\n",
    "Now we can use the polynomial model to estimate the distance between the earthquake and the seismograph based on the S-P time difference you picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the model to predict the distance. Hint: use the `[[ ]]` to pass in the S-P time difference as a vertical array\n",
    "distance_km = model.predict(\n",
    "\n",
    "## Print the estimated distance\n",
    "print(f'The estimated distance is {distance_km[0][0]:.2f} km')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From reading the seismograph, you can successfully pick the P and S wave arrival times and use them to estimate the distance to the earthquake.\n",
    "\n",
    "How does the estimate of distance compare to the true earthquake epicenter distance that you calculated using the `geopy` `distance.distance()`? \n",
    "\n",
    "If the errors are within 15%, you did a good job picking the P and S wave arrival times.\n",
    "If they are very different you may want to reconsider your P and S wave arrival times and recompute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we only used one seismograph station to estimate the distance to the earthquake. In practice, we use data from many stations to estimate the earthquake location.\n",
    "\n",
    "The earthquake locations that we used in the first part of the assignment are determined thorugh computing the distance from the earthquake for at least three stations as illustrated below. \n",
    "\n",
    "With three stations, we can form a triangle and determine the location of the earthquake by finding the point that is equidistant from all three stations.\n",
    "\n",
    "<img src=\"images/IRIS_eq_tri.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Earthquake Occurrence Statistics (Aftershocks)\n",
    "\n",
    "In this section, we will further explore the earthquake catalog data and compute the earthquake occurrence statistics: Omori's Law and Gutenberg-Richter Law.\n",
    "\n",
    "These information will be useful for understanding the earthquake hazard and making earthquake forecasts.\n",
    "\n",
    "There are two primary statistics that describe earthquake catalog data. \n",
    "\n",
    "The first is Gutenberg-Richter, which is used to characterize the rates of primary earthquakes over some period of time to determine rates of occurence, which can then be used to assess hazard and make earthquake forecasts.\n",
    "\n",
    "$$ log_{10}N(M) = A - b \\cdot M $$\n",
    "\n",
    "where $N(M\n",
    "\n",
    "The second is Omori's Law which describes the distribution of aftershocks following a primary earthquake or mainshock. It can be used to estimate the rate of aftershock production over time after the earthquake.\n",
    "\n",
    "$$ N(t) = \\frac{k}{(c + t)^p} $$\n",
    "\n",
    "<!-- $$ log_{10}N(t) = log_{10}k - p \\cdot log_{10}(c + t) $$ -->\n",
    "\n",
    "where $N(t)$ is the number of aftershocks at time $t$, $k$ is a constant, $c$ is the time at which the aftershock production rate peaks, and $p$ is the decay rate.\n",
    "\n",
    ")$ is the number of earthquakes with magnitude greater than or equal to $M$, $A$ is the intercept, and $b$ is the slope.\n",
    "\n",
    "\n",
    "<!-- - Load a Bay Area seismic catalog of January 01,1989 to December 31, 1995.\n",
    "- Compute the distance and time interval between Loma Prieta quake and subsequant earthquakes to indentify aftershocks.\n",
    "- Filter the aftershocks from the catalog and look at their distribution.\n",
    "- Examine the Gutenberg-Richter statistic\n",
    "- Make and earthquake forecast -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at earthquakes that occurred close to Berkeley.\n",
    "\n",
    "In particular, on October 17 at 5:15pm PDT (October 18 1989 at 04:15am UTC) the M6.9 Loma Prieta earthquake occurred in the Santa Cruz mountains approximately 80 km southwest of the Berkeley Campus. \n",
    "\n",
    "We will use the earthquake catalog in the Bay Area and aftershocks of the Loma Prieta earthquake to examine the earthquake statistics.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/84/USGS_Shakemap_-_1989_Loma_Prieta_earthquake_%28June_1988_foreshock%29.jpg\" width=30%>\n",
    "\n",
    "https://en.wikipedia.org/wiki/1989_Loma_Prieta_earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the Earthquake Catalog \n",
    "\n",
    "Load the .csv data file of all the earthquakes from January 01,1989 to December 31, 1995 in the ANSS (Advanced National Seismic System) catalog from between latitudes 36.0-38.5° and longitude -123.0 to -121.0° ([http://ncedc.org/anss/catalog-search.html](http://ncedc.org/anss/catalog-search.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Earthquake Catalog\n",
    "catalog = pd.read_csv(    #data/bay_area_anss_1989_1995.csv'\n",
    "\n",
    "## Convert the DateTime column to a datetime object\n",
    "catalog['DateTime'] = pd.to_datetime(\n",
    "\n",
    "## Preview the catalog\n",
    "catalog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we will start by plotting the earthquake catalog on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coordinates for UC Berkeley\n",
    "Berk_lat = 37.8716\n",
    "Berk_lon = -122.2727\n",
    "\n",
    "## Coordinates for the map\n",
    "lat0=36.0\n",
    "lat1=38.5\n",
    "lon0=-123.0\n",
    "lon1=-121.0\n",
    "\n",
    "## Make a map using cartopy\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([lon0, lon1, lat0, lat1], crs=ccrs.PlateCarree())\n",
    "\n",
    "## Plot the entire catalog\n",
    "plt.scatter(\n",
    "\n",
    "## Add coastlines\n",
    "ax.coastlines(resolution='10m',linewidth=1)\n",
    "\n",
    "## Add Berkeley Campus. Remember to add `label='Berkeley Campus'` to the scatter plot.\n",
    "plt.scatter(\n",
    "\n",
    "## Add x and y labels\n",
    "ax.set_xlabel('\n",
    "ax.set_ylabel('\n",
    "\n",
    "## Add legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Earthquake frequency vs magnitude\n",
    "\n",
    "Let's first look at the earthquake frequency vs magnitude for the entire catalog. \n",
    "\n",
    "\n",
    "Based on the Gutenberg-Richter Law, we expect a linear relationship between the logarithm of the number of earthquakes and the magnitude.\n",
    "\n",
    "$$ log_{10}N(M) = A - b \\cdot M $$\n",
    "\n",
    "You can use `plt.hist()` to plot the histogram of `LP_catalog['Magnitude']`. Use `log=True` to plot the histogram on a log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "## Plot the histogram of earthquake frequency vs magnitude. Use `log=True` to plot the histogram on a log scale.\n",
    "plt.hist(\n",
    "\n",
    "## Add x-axis label and y-axis label\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Does the histogram follow a linear relationship? Can you approximate the slope and intercept of the linear relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a more accurate estimate of the slope and intercept of the linear relationship. \n",
    "\n",
    "Recall the linear regression model from the lecture, let's use `LinearRegression()` to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use the np.histogram function to get the frequency of each magnitude bin. Using bins=40.\n",
    "magnitude_bins = np.arange(0, 6, 0.1)\n",
    "frequency, _ = np.histogram(catalog['Magnitude'], bins=magnitude_bins)\n",
    "magnitude_bins = (magnitude_bins[:-1] + magnitude_bins[1:]) / 2 ## convert the bin edges to the bin centers\n",
    "\n",
    "## Define the input and output variables. Hint: use `np.log10(frequency)` to take the logarithm of the frequency\n",
    "X = \n",
    "y = \n",
    "\n",
    "## filter out the inf values\n",
    "X = X[~np.isinf(y)]\n",
    "y = y[~np.isinf(y)]\n",
    "\n",
    "## Reshape the input and output variables to be vertical arrays and replace inf with 0\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "## Fit a linear model using LinearRegression() from sklearn\n",
    "model = \n",
    "model.fit(\n",
    "\n",
    "## Get prediction from the model\n",
    "y_pred = model.predict(\n",
    "\n",
    "## Evaluate the model using r2_score\n",
    "R_squared = \n",
    "print(f'The model R-squared is {R_squared:.2f}')\n",
    "\n",
    "## Plot the prediction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, label='Data')\n",
    "plt.plot(X, y_pred, color='red', label='Linear Regression')\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Does the linear model fit the data well? Pay attention to the small magnitude earthquakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason the model does not fit well at the small magnitude earthquakes (M < 1) is because the earthquake catalog is not complete for small magnitude earthquakes meaning that there are many small magnitude earthquakes that are not recorded in the catalog because of many reasons such as the earthquakes are too far away from the seismic stations, the earthquakes are too weak to be recorded by the seismographs, and the background noise level is too high for automatic algorithms to identify the earthquakes.\n",
    "\n",
    "To fix the fit, let's only fit the data for M >= 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use the np.histogram function to get the frequency of each magnitude bin. Using bins=40.\n",
    "magnitude_bins = np.arange(0, 6, 0.1)\n",
    "frequency, _ = np.histogram(catalog['Magnitude'], bins=magnitude_bins)\n",
    "magnitude_bins = (magnitude_bins[:-1] + magnitude_bins[1:]) / 2 ## convert the bin edges to the bin centers\n",
    "\n",
    "## Define the input and output variables. Hint: use `np.log10(frequency)` to take the logarithm of the frequency\n",
    "X = \n",
    "y = \n",
    "\n",
    "## Filter the input and output variables to only include the data for M >= 1\n",
    "y = y[\n",
    "X = X[\n",
    "\n",
    "## filter out the inf values\n",
    "X = X[~np.isinf(y)]\n",
    "y = y[~np.isinf(y)]\n",
    "\n",
    "## Reshape the input and output variables to be vertical arrays and replace inf with 0\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "## Fit a linear model using LinearRegression() from sklearn\n",
    "model = \n",
    "model.fit(\n",
    "\n",
    "## Get prediction from the model\n",
    "y_pred = model.predict(\n",
    "\n",
    "## Evaluate the model using r2_score\n",
    "R_squared = \n",
    "print(f'The model R-squared is {R_squared:.2f}')\n",
    "\n",
    "## Plot the prediction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, label='Data')\n",
    "plt.plot(X, y_pred, color='red', label='Linear Regression')\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the slope and intercept of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the slope and intercept\n",
    "slope = \n",
    "intercept = \n",
    "\n",
    "print(f'The slope is {slope:.2f} and the intercept is {intercept:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How much does the fit improve? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What is the slope and intercept of the linear model? Can you estimate the A-value and b-value of the Gutenberg-Richter Law? \n",
    "\n",
    "$$ log_{10}N(M) = A - b \\cdot M $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the aftershocks of the Loma Prieta earthquake.\n",
    "\n",
    "First, we need to extract the period of the Loma Prieta earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the earthquake origin time, latitude, and longitude (https://earthquake.usgs.gov/earthquakes/eventpage/nc216859/executive)\n",
    "earthquake_origin_time = pd.to_datetime('1989-10-18 00:04:15')\n",
    "earthquake_latitude = 37.036\n",
    "earthquake_longitude = -121.885\n",
    "\n",
    "## Define a new column of days since the earthquake origin time. \n",
    "catalog['days_since_earthquake'] = (catalog['DateTime'] - earthquake_origin_time).dt.days\n",
    "\n",
    "## Extract the earthquakes within 0.1 degree from the earthquake origin and within 90 days from the earthquake origin time\n",
    "LP_catalog = catalog[\n",
    "    (catalog['days_since_earthquake'] >= ) & \n",
    "    (catalog['days_since_earthquake'] <= ) & \n",
    "    (catalog['Latitude'] >= ) & \n",
    "    (catalog['Latitude'] <= ) & \n",
    "    (catalog['Longitude'] >= ) & \n",
    "    (catalog['Longitude'] <= )\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot magnitude vs. time for the aftershock events\n",
    "\n",
    "You can try to use `s=LP_catalog['Magnitude']` to scale the marker size by magnitude, or `c=LP_catalog['Magnitude']` to color the marker by magnitude, cmap='plasma' seems to be a nice color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the figure size wide using `figsize=(20, 6)`\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "## Plot the Loma Prieta aftershock catalog between 'DateTime' and 'Magnitude'. Hint: adjust the color and size of the markers to make the plot more informative\n",
    "plt.scatter(\n",
    "\n",
    "## Add a color bar\n",
    "plt.colorbar(label='Magnitude')\n",
    "\n",
    "## Add x-axis label and y-axis label\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How would you describe the distribution of large earthquake magnitudes with time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot earthquake frequency vs time\n",
    "\n",
    "You can use `plt.hist()` to plot the histogram of `days_since_earthquake`. Use `log=True` to plot the histogram on a log scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "## Plot the histogram of earthquake frequency vs time. Use `log=True` to plot the histogram on a log scale.\n",
    "plt.hist(\n",
    "\n",
    "## Add x-axis label and y-axis label\n",
    "plt.xlabel('\n",
    "plt.ylabel('\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How would you describe the distribution of number of aftershocks with time after the main quake?\n",
    "\n",
    "By how much is the rate of aftershock occurrence reduced after 7 days? After 30 days? Note that the y-axis is on a log scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "- Earthquake recurrence in the San Francisco Bay Area\n",
    "\n",
    "Both the Gutenberg-Richter Law and Omori's Law are very important for understanding the earthquake recurrence in a region.\n",
    "\n",
    "Recall the lecture about probability of earthquake occurrence in [08 probability](https://ai4eps.github.io/EPS88_PyEarth/lectures/08_probabilities/#extension-earthquake-probability).\n",
    "\n",
    "Based on the 120 year catalog, we can estimate the average recurrence interval for magnitude 5.0, 6.0, 7.0 and 8.0 events in the San Francisco Bay Area. \n",
    "\n",
    "The bay area is located on the San Andreas Fault, which is the boundary between the Pacific and North American tectonic plates.\n",
    "\n",
    "You can read more information about earthquake hazard of the San Andreas Fault from the USGS website:\n",
    "\n",
    "https://www.usgs.gov/natural-hazards/earthquake-hazards/science/back-future-san-andreas-fault?qt-science_center_objects=0#qt-science_center_objects\n",
    "\n",
    "Although we can not predict when and where the next big earthquake will happen, understanding the earthquake recurrence can help us prepare for the earthquake and mitigate the earthquake risk.\n",
    "\n",
    "Earthquake forecasting and earthquake risk assessment is an important topic in the field of earthquake engineering.\n",
    "\n",
    "You can read more about earthquake forecasting and risk assessment from our BLS website:\n",
    "\n",
    "https://seismo.berkeley.edu/research/eew_basics.html\n",
    "\n",
    "<img src=\"images/fault_map.png\" width=700>\n",
    "\n",
    "Map of Bay Area faults. \n",
    "Source: https://pubs.er.usgs.gov/publication/fs20163020\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
