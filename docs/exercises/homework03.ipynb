{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 03 of EPS 88\n",
    "\n",
    "## Learning from a bigger classification of basalt source\n",
    "\n",
    "In the 2006 paper\n",
    "\n",
    ">Vermeesch, P. (2006). Tectonic discrimination of basalts with classification trees. Geochimica et Cosmochimica Acta, 70, 1839-1848. https://doi.org/10.1016/j.gca.2005.12.016\n",
    "\n",
    "Vermeesch wrote:\n",
    "\n",
    "> *\"If a much larger database were compiled, the trees would grow and their discriminative power increase, but they would still be easy to interpret\"*\n",
    "\n",
    "In a more recent paper, Doucet et al. compiled many more data. Rather than 756 basalt data points, they compiled 29,407 of which 22,005 correspond to the categories of Vermeesch (2006).\n",
    "\n",
    "> Doucet, L. S., Tetley, M. G., Li, Z.-X., Liu, Y., & Gamaleldien, H. (2022). Geochemical fingerprinting of continental and oceanic basalts: A machine learning approach. Earth-Science Reviews, 233, https://doi.org/10.1016/j.earscirev.2022.104192\n",
    "\n",
    "Your task in this assignment is use the data of Doucet et al. (2022) to evaluate whether the predictive power of the classification tree approach increases within this increase in data size as predicted by Vermeesch (2006)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scientific Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "We will import the data from Doucet et al. 2022 that is provided as their supplemental table 1.\n",
    "\n",
    "For comparison, we will also import the data from Vermeesch (2006)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Doucet et al. 2022 data\n",
    "Doucet_data = pd.read_csv('data/Doucet2022.csv',header=11)\n",
    "\n",
    "## Read Vermeesch (2006) data\n",
    "Vermeesch_data = pd.read_csv('data/Vermeesch2006.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data\n",
    "\n",
    "As we have two dataframes, if we want to develop a machine learning model that can be applied to both datasets, we need to make sure that the column names (feature names) are the same.\n",
    "\n",
    "Let's first inspect the column names of the two dataframes. If they are different, we need to make them the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the column names\n",
    "print(  ## Doucet et al. 2022\n",
    "print(  ## Vermeesch (2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the column names are different. We need to make them the same.\n",
    "\n",
    "There are multiple ways for data cleaning. Here we will use the following steps:\n",
    "\n",
    "1. Rename the 'affinity' column to 'type' in the Vermeesch dataframe to match the column name in the Doucet dataframe\n",
    "2. Remove the units from the column names\n",
    "3. Keep only the columns that are present in both dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename type to affinity for Doucet data\n",
    "Vermeesch_data.rename(columns={'affinity':'type'},inplace=True)\n",
    "print(Vermeesch_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove _ppm from the column names\n",
    "Doucet_data.columns = Doucet_data.columns.str.replace('_ppm', '')\n",
    "Vermeesch_data.columns = Vermeesch_data.columns.str.replace('_ppm', '')\n",
    "\n",
    "## remove _wt_percent from the column names\n",
    "Doucet_data.columns = Doucet_data.columns.str.replace('_wt_percent', '')\n",
    "Vermeesch_data.columns = Vermeesch_data.columns.str.replace('_wt_percent', '')\n",
    "\n",
    "print(Doucet_data.columns)\n",
    "print(Vermeesch_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep common columns between Doucet and Vermeesch data\n",
    "common_columns = list(set(Doucet_data.columns) & set(Vermeesch_data.columns))\n",
    "\n",
    "Doucet_data = Doucet_data[common_columns]\n",
    "Vermeesch_data = Vermeesch_data[common_columns]\n",
    "\n",
    "print(Doucet_data.columns)\n",
    "print(Vermeesch_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we simply keep the common columns between the two dataframes, which loss some information. \n",
    "If you want to keep all the information, you could further explore how to rename the columns in a way that can be used for both dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Doucet et al. 2022 study includes data from additional basalt types. To test Vermeesch's hypothesis, let's filter the data to be those from:\n",
    "\n",
    "- ***Island arc basalts (IAB)*** *In the Doucet et al. dataset these are called `ARC-O` standing for oceanic arc.*\n",
    "- ***Mid-ocean ridge (MORB)***\n",
    "- ***Ocean-island (OIB)***\n",
    "\n",
    "The code below filters to these types and creates a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter the data \n",
    "Doucet_data = Doucet_data[(Doucet_data['type']=='MORB') | (Doucet_data['type']=='OIB') | (Doucet_data['type']=='ARC-O')].reset_index(drop=True)\n",
    "Doucet_data.head()\n",
    "\n",
    "## To make the column names consistent with Vermeesch (2006), let's rename the type names \"ARC-O\" to \"IAB\"\n",
    "Doucet_data.loc[Doucet_data['type']=='ARC-O','type'] = 'IAB'\n",
    "Doucet_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Recall the data preprocessing steps we used in the previous class:\n",
    "\n",
    "- Encode the target variable 'type' using LabelEncoder\n",
    "- Split the data into features (X) and target (y)\n",
    "- Impute missing values using median imputation\n",
    "- Split the data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode the target variable 'type' using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# we seperate fit and transform calls, so that we can use the same label encoder for both datasets\n",
    "le.fit(\n",
    "\n",
    "## Split the data into features (X) and target (y)\n",
    "X = Doucet_data.drop('type',axis=1)\n",
    "X_columns = X.columns ## save the column names\n",
    "y = Doucet_data['type']\n",
    "\n",
    "## apply le.transform to convert y from string to integer\n",
    "y =  \n",
    "\n",
    "## Impute missing values using median imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "#we seperate fit and transform calls, so that we can use the same imputer for both datasets\n",
    "imputer.fit( \n",
    "#apply imputer.transform to fill in the missing values\n",
    "X = \n",
    "\n",
    "## Split the data into training and testing sets. Use 30% of the data as the testing set. Set random_state=42\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n",
    "## Let's check the shape of the training and testing sets\n",
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_test.shape = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a logistic regression classifier\n",
    "\n",
    "Review the previous lectures on logistic regression and how to build a logistic regression classifier using `sklearn`.\n",
    "\n",
    "Try to build a logistic regression classifier and evaluate its accuracy using Doucet et al. (2022) data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a logistic regression classifier using LogisticRegression(solver=\"liblinear\")\n",
    "## remember to use make_pipeline and StandardScaler to standardize the data\n",
    "model_linear = \n",
    "\n",
    "## train the model\n",
    "model_linear.fit(\n",
    "\n",
    "## predict on the test set\n",
    "y_pred = \n",
    "\n",
    "## evaluate the model\n",
    "accuracy = \n",
    "print(f\"{accuracy = }\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SVM classifier\n",
    "\n",
    "Let's try to use the more advanced machine learning models SVM to see if they can improve the accuracy.\n",
    "\n",
    "First, let's try a linear kernel SVM, which is similar to the logistic regression classifier we built above. \n",
    "\n",
    "Review the previous lectures on SVM and how to build a SVM classifier using `sklearn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a SVM classifier using SVC(kernel=\"linear\")\n",
    "## remember to use make_pipeline and StandardScaler to standardize the data\n",
    "model_svm = \n",
    "\n",
    "## train the model\n",
    "model_svm.fit(\n",
    "\n",
    "## predict on the test set\n",
    "y_pred = \n",
    "\n",
    "## evaluate the model\n",
    "accuracy = \n",
    "print(f\"{accuracy = }\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we dicussed in class, the advantage of SVM is that it can handle non-linear decision boundaries. Let's try a RBF kernel SVM.\n",
    "\n",
    "The RBF kernel SVM is more computationally expensive than the linear kernel SVM, but it can handle non-linear decision boundaries.\n",
    "\n",
    "The gamma parameter controls the smoothness of the decision boundary. A large gamma value will create a more complex decision boundary, while a small gamma value will create a simpler decision boundary.\n",
    "\n",
    "First build a SVM classifier using a default gamma value of 0.1.\n",
    "\n",
    "Then try a different gamma value and see if you can find a better model. \n",
    "\n",
    "Report the best gamma value and the accuracy of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a SVM classifier using SVC(kernel=\"rbf\",gamma=0.1)\n",
    "## Remember to use make_pipeline and StandardScaler to standardize the data\n",
    "model_svm = \n",
    "\n",
    "## train the model\n",
    "model_svm.fit(\n",
    "\n",
    "## predict on the test set\n",
    "y_pred = \n",
    "\n",
    "## evaluate the model\n",
    "accuracy = \n",
    "print(f\"{accuracy = }\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a decision tree classifier\n",
    "\n",
    "Review the previous lectures on decision tree and how to build a decision tree classifier using `sklearn`.\n",
    "\n",
    "Similar to the gamma parameter in SVM, the `max_depth` parameter in decision tree can also affect the complexity of the model.\n",
    "\n",
    "The default setting is `max_depth=None` which means it will keep going and going until the leafs of the tree contain a single category. \n",
    "\n",
    "First, let's build a decision tree classifier with the default setting.\n",
    "\n",
    "Then try different `max_depth` values and see if you can find a better model.\n",
    "\n",
    "Report the best `max_depth` value and the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a decision tree classifier with default setting DecisionTreeClassifier(max_depth=None)\n",
    "## No need to standardize the data for decision tree\n",
    "model_tree = \n",
    "\n",
    "## train the model\n",
    "model_tree.fit(\n",
    "\n",
    "## predict on the test set\n",
    "y_pred = \n",
    "\n",
    "## evaluate the model\n",
    "accuracy = \n",
    "print(f\"{accuracy = }\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in class, the decision tree classifier is a white box model, which means we can understand the importance of each feature in the decision making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the most important features\n",
    "feature_importances = model_tree.feature_importances_\n",
    "feature_df = pd.DataFrame({'feature':X_columns,'importance':feature_importances})\n",
    "feature_df = feature_df.sort_values(by='importance',ascending=False)\n",
    "feature_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the accuracy of the decision tree based on larger dataset from Doucet et al. (2022) compare to that using the smaller dataset from Vermeesch (2006)? Write your answer in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What similarities and differences are there between the importance of different data fields (feature importance) between the decision tree built on the Vermeesch (2006) data compilation vs that built on the Doucet et al. (2022) data compilation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the model trained on Doucet et al. (2022) dataset to the Vermeesch (2006) dataset\n",
    "\n",
    "The goal of machine learning is to generalize the model to new data. Here we will apply the decision tree classifier trained on the Doucet et al. (2022) dataset to the Vermeesch (2006) dataset to see how well the model can be applied to new data.\n",
    "\n",
    "Let's apply the linear model, SVM, and decision tree classifier to the Vermeesch (2006) dataset and evaluate their accuracy.\n",
    "\n",
    "Please note that you would need to preprocess the Vermeesch (2006) dataset in the same way as the Doucet et al. (2022) dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the Vermeesch (2006) dataset\n",
    "## Split the data into features (X) and target (y)\n",
    "X = Vermeesch_data.drop('type',axis=1)\n",
    "X = X[X_columns] ## keep column in the same order as Doucet et al. (2022) dataset\n",
    "y = Vermeesch_data['type']\n",
    "y = le.transform(y) ## reuse the label encoder we defined earlier\n",
    "\n",
    "## Impute missing values using median imputation \n",
    "#use the same imputer we defined earlier\n",
    "X = imputer.transform(X) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the linear model and evaluate the accuracy\n",
    "y_pred = \n",
    "accuracy = accuracy_score(y,y_pred)\n",
    "print(f\"Logistic regression accuracy: {accuracy:.3f}\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the SVM model and evaluate the accuracy\n",
    "y_pred = \n",
    "accuracy = accuracy_score(y,y_pred)\n",
    "print(f\"SVM accuracy: {accuracy:.3f}\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the decision tree model and evaluate the accuracy\n",
    "y_pred = \n",
    "accuracy = accuracy_score(y,y_pred)\n",
    "print(f\"Decision tree accuracy: {accuracy:.3f}\")\n",
    "\n",
    "## plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Comment on how well these models perform on the Vermeesch (2006) dataset. Why do you think the models perform better or worse on the Vermeesch (2006) dataset? -->\n",
    "Based on the accuracy, please comment on the following questions:\n",
    "\n",
    "- How does the accuracy of models trained on Doucet et al. (2022) dataset compare to the model trained on Vermeesch (2006) dataset?\n",
    "Recall the accuracy you get in previous class using the model trained on Vermeesch (2006) dataset.\n",
    "\n",
    "- Among these models, which one performs the best on the Doucet et al. (2022) dataset and which one performane the worst? \n",
    "Similar question for the Vermeesch (2006) dataset. Are the best and worst models the same or totally different?\n",
    "\n",
    "- What are the possible reasons for the difference in accuracy?  What does this imply for the predictive power of machine learning models? Hint: think about model fitting and generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
