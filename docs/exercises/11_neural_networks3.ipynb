{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f21e76-5605-4d3f-a7d7-d3a3801da14d",
   "metadata": {},
   "source": [
    "# Finetuning AlexNet for Volcanic Deformation Classification\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4EPS/EPS88_PyEarth/blob/master/docs/lectures/11_neural_networks3.ipynb\">\n",
    "<img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "\n",
    "**Note**: If you are running this in [a colab notebook](https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb), we recommend you enable a free GPU by going:\n",
    "\n",
    "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
    "\n",
    "This tutorial demonstrates how to fine-tune a pre-trained AlexNet model on the LICS dataset, which consists of volcanic InSAR (Interferometric Synthetic Aperture Radar) images. \n",
    "\n",
    "The dataset contains 6,808 images, divided into two categories: 3,605 images displaying deformation signals (class 1 'volcano_deformation') and 3,203 images without deformation signals (class 0 'background_noise'). Originally, the pre-trained AlexNet was designed to classify 1,000 types of natural objects, such as tables, cars, dogs, etc. \n",
    "\n",
    "In this tutorial, we will modify the final layer of the neural network to classify images into just two classes instead of the original 1,000.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/zhuwq0/images/main/alexnet.png' style='width: 50%'/>\n",
    "\n",
    "Created by Robert Gabriel Popescu and Juliet Biggs, University of Bristol, UK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be9b42-6413-4f67-8460-2c77aa6bd4ec",
   "metadata": {},
   "source": [
    "## LiCS Dataset ##\n",
    "\n",
    "<!-- You can download the dataset at [LiCS dataset](https://zenodo.org/records/14161590) or by pressing on this link: [download](https://zenodo.org/records/14161590/files/LiCS.zip).  -->\n",
    "\n",
    "Download and Unzip the dataset and make sure the folder *LiCS* has two subfolders: *background_noise* and *volcano_deformation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if not os.path.exists('LiCS'):\n",
    "    if not os.path.exists('LiCS.zip'):\n",
    "        !wget https://github.com/AI4EPS/EPS88_PyEarth/releases/download/LiCS/LiCS.zip\n",
    "    !unzip LiCS.zip\n",
    "else:\n",
    "    print(\"File already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d6a6c-71a0-47dd-b612-780410442fd2",
   "metadata": {},
   "source": [
    "## Imports ##\n",
    "\n",
    "We will import the necessary libraries:\n",
    "- *torch* is the main library that will run the Artificial neural network, called **PyTorch**\n",
    "- *matplotlib* is for creating graphs\n",
    "- *numpy* is for storying arrays of data. A few other libraries work only with this (such as matplotlib)\n",
    "- *sklearn* is a machine learning library that we will use to separate the dataset into train and test\n",
    "- *torchvision* is a library for loading images as datasets to be used by **PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b3f57-d31b-4852-ab7e-dc285c285c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set random seed\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588afef-2f6c-48ac-861c-818b8c5d1eea",
   "metadata": {},
   "source": [
    "## Running the models on the GPU ##\n",
    "We want to run the code on the GPU if possible. Artifial neural networks work faster on a GPU so we will select the device **cuda** if it is available. Alternatively, if you are using a Mac, you want to select **mps**.\n",
    "\n",
    "If you encounter problems with the memory, manually setting this to the CPU will solve the problem, but it will also slow down the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444054b7-9cc4-4e77-b5ec-dd504ad426a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the model on the GPU if possible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# If you get errors about CUDA running out of memory, you can set it to run on the CPU by uncommenting the next line.\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea23f3-b967-4d76-aeec-50b56755f617",
   "metadata": {},
   "source": [
    "## Loading the dataset ##\n",
    "We will load the **LICS** dataset that contains two folders, one with images of **volcano deformation** and one with images of **background noise**. If the dataset is not in the same folder as this notebook, change *dataset_dir* to the correct path of the dataset.\n",
    "\n",
    "We need to define the transformations that will be applied to the images. In this case, we will only transform the images into **tensors**, which is how **PyTorch** stores and uses data. This will also bring the images from the interval [0,255] (the interval used to store RGB images) to [0,1]. Neural networks work better with small numbers, ideally between the interval [-1,1] or [0,1].\n",
    "\n",
    "Tensors are a specialized data structure that is similar to arrays and matrices. Tensors are used to encode the inputs and outputs of a model, as well as the parameters of the model. Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. They are also optimized for automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5a491-aa72-4c79-92b3-c543e830699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "dataset_dir = 'LiCS'\n",
    "\n",
    "# Transformers applied to the dataset\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_dir, transform=data_transforms)\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Show information about the dataset\n",
    "print(f'Dataset size: {len(dataset)}')\n",
    "print(f'Mapping from class names to indexes: {dataset.class_to_idx}')\n",
    "print(f'Number of samples per class: {dict(Counter(dataset.targets))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebe68e",
   "metadata": {},
   "source": [
    "## Visualizing the dataset ##\n",
    "\n",
    "We will create a function to visualize some of the images inside the dataset. Then we will load some images using the train dataloader and visualize them.\n",
    "\n",
    "The images are wrapped InSAR interferograms. Each fringe represents 2.8 cm of displacement. The images are automatically processed from satellite data. You can read more about InSAR images [here](https://en.wikipedia.org/wiki/Interferometric_synthetic-aperture_radar).\n",
    "\n",
    "Watch this video to understand how InSAR works: [link](https://youtu.be/SLMWzQQv90s?si=byqpNh92ikN0xOrq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39752319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(images, labels, show_labels=False):\n",
    "    num_cols = 4\n",
    "    num_rows = (len(images) - 1) // num_cols + 1\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(4 * num_cols, 4 * num_rows), squeeze=False)\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            idx = i * num_cols + j\n",
    "            if idx < len(images):\n",
    "                image = images[idx][0]\n",
    "                image = image * 2 * np.pi - np.pi\n",
    "                axs[i, j].imshow(image, cmap='jet', vmin=-np.pi, vmax=np.pi)\n",
    "                if show_labels:\n",
    "                    axs[i, j].set_title(class_names[labels[idx]])\n",
    "                axs[i, j].axis('off')\n",
    "            else:\n",
    "                axs[i, j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_per_class = 10\n",
    "noise_indices = [i for i, label in enumerate(dataset.targets) if label == 0][:num_samples_per_class]\n",
    "volcano_indices = [i for i, label in enumerate(dataset.targets) if label == 1][:num_samples_per_class]\n",
    "indices = noise_indices + volcano_indices\n",
    "random.shuffle(indices)\n",
    "images, labels = zip(*[dataset[i] for i in indices])\n",
    "plot_example(images, labels, show_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a341977",
   "metadata": {},
   "source": [
    "Question: Based on the images, can you tell which images are from the class 'volcano_deformation' and which are from the class 'background_noise'? How can you tell the difference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8edd2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "465337ce",
   "metadata": {},
   "source": [
    "Question: Pass ```show_labels=True``` to the function and run the code again to show the ground truth labels of the images. Do the labels match your prediction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ec14f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf022536",
   "metadata": {},
   "source": [
    "Now let's see if we can also train a neural network to differentiate between the two classes. \n",
    "If we can, we can use this neural network to automatically detect volcanic deformation signals in InSAR images.\n",
    "As you can imagine, the InSAR satellites are taking thousands of images every day, and it is impossible for a human to look at all of them. This is where the neural network and machine learning come in handy.\n",
    "\n",
    "Recall what we learned in the previous lectures about neural networks. We will folow a similar approach to build a neural network that can differentiate between the two classes of images for automatic detection of volcanic deformation signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65460008-975e-479d-aae9-1aaae703ec49",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test ##\n",
    "\n",
    "**PyTorch** allows us to split a dataset into two parts only at random, so if we want to have the same number of images from each class into both the train and the test dataset, we need to use a function from **sklearn**: *train_test_split*.\n",
    "\n",
    "In general, the size of the test dataset is much smaller than the training dataset. Here we use a training dataset that is ten times bigger than the test. The optimum split depends on the use case, the model used, the size of the dataset, etc., but a generally good split is 80% train and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795b4ba-e803-402e-a3d0-f9bcef4b1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = 2000\n",
    "test_dataset_size = 200\n",
    "\n",
    "targets = np.array(dataset.targets)\n",
    "# The two classes are unbalanced with 'volcano_deformation' having more images. Thus we remove some of them. \n",
    "# All the 3203 'background_noise' images are in front, followed by the 3605 'volcano_deformation' images. \n",
    "# So from the array with all the images, we can select the first 6406 images, which is all the 'background_noise' ones followed by 3203 'volcano_deformation' ones.\n",
    "# Thus, we select the first 6406 images from the dataset.\n",
    "targets = targets[:6406]\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(targets.shape[0]),\n",
    "    train_size=train_dataset_size,\n",
    "    test_size=test_dataset_size,\n",
    "    stratify=targets,\n",
    ")\n",
    "\n",
    "# We use the splits we obtained to create subsets of the main dataset, one for train and one for test\n",
    "train_dataset = Subset(dataset, indices=train_indices)\n",
    "test_dataset = Subset(dataset, indices=test_indices)\n",
    "\n",
    "# Show information about our subsets\n",
    "train_classes = [dataset.targets[i] for i in train_dataset.indices]\n",
    "print(f'Numner of samples per class for the train dataset: {dict(Counter(train_classes))}')\n",
    "\n",
    "test_classes = [dataset.targets[i] for i in test_dataset.indices]\n",
    "print(f'Numner of samples per class for the test dataset: {dict(Counter(test_classes))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e178fc-2046-4527-8e06-d26c2492c59f",
   "metadata": {},
   "source": [
    "## Creating a DataLoader ##\n",
    "\n",
    "A **DataLoader** is responsible for loading the data, in our case images, from the disk into memory during training or testing. \n",
    "\n",
    "We need to decide how many images are loaded at once by setting *batch_size*. The *batch_size* option influences how fast and efficient the model trains, but a bigger batch size also means more memory is required. A bigger batch size can also yield higher accuracy.\n",
    "\n",
    "The argument *shuffle* decides if the order in which the images are loaded is random or not. We will make the order random for training but not for testing. Making the order random when training can boost the final accuracy of the model.\n",
    "\n",
    "Here, the batch size is set to 2. You can increase this number if you run the program on a GPU or a strong CPU.\n",
    "\n",
    "#### If you get an error like this: *torch.cuda.OutOfMemoryError: CUDA out of memory*, one way of solving it is to choose a smaller number for the *batch_size* option. If this doesn't work, as a last resort, you can choose to run the model on the CPU instead of the GPU from the second code cell. ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0110a0b-d5a8-4f35-99b6-54e37ee3886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    # shuffle=False\n",
    "    shuffle=True ## just for visualization purposes\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9cc6176-c50c-43dc-8d27-8a7c622f1035",
   "metadata": {},
   "source": [
    "## Training an Artificial Neural Network ##\n",
    "\n",
    "### Introduction ###\n",
    "Artificial Neural Networks, or ANNs for short, are Machine Learning models inspired by biological neural networks that are found in animal brains. \n",
    "\n",
    "An ANN is a collection of nodes called artificial neurons that abstract the neurons found in a brain. An artificial neuron, like its biological counterpart, receives signals from other neurons, processes them and sends its own signal to other neurons connected to it. The signal, or the input, received from a connection with another neuron is a real number, and each connection has a weight associated with it that is adjusted during training. The output of the neuron is computed by applying a non-linear function to the weighted sum of the inputs. Neurons are generally grouped into layers and each layer may perform a different transformation to its inputs. The first layer is called the input layer and it has the same number of neurons as the number of dimensions of the input. The last layer is called the output layer and the layers in-between are known as hidden layers. An example of a network is presented in the figure below. \n",
    "\n",
    "<div>\n",
    "<center><img src=\"https://raw.githubusercontent.com/zhuwq0/images/main/ann.png\" width=\"800\" alt=\"ANN\"/></center>\n",
    "</div>\n",
    "\n",
    "In our case, the input is an RGB image of size 227x227. Since RBG images have 3 channels for colours, each pixel has 3 values, so our input layer has 3x227x227=154587 neurons.\n",
    "For the network that we will use, the hidden layers are fixed. We will modify the output layer to have 2 neurons.\n",
    "\n",
    "The model for one neuron is:\n",
    "\\begin{align*}\n",
    "y = \\varphi(\\sum_{i} w_i x_i - b)\n",
    "\\end{align*}\n",
    "where $x_i$ is the i<sup>th</sup> input received, $w_i$ is the weight adjusting that input, $\\varphi$ is a non-linear function, $b$ is the bias and $y$ is the output.\n",
    "\n",
    "The input of the network is a feature vector $\\mathbf{x} = \\mathbf{x}^0$. Denoting all the weights of a neuron as $\\mathbf{w} = [w_0, w_1, \\dots]$ and the weights of all neurons in a layer as $W = [\\mathbf{w_0}, \\mathbf{w_1}, \\dots]$, the output of a layer $l$ can be written as: \n",
    "\\begin{align*}\n",
    "\\mathbf{y}^l = \\varphi(W^l \\mathbf{x}^l - \\mathbf{b}^l)\n",
    "\\end{align*}\n",
    "The output of the network will be a vector $\\mathbf{y}^N$, with $N$ being the number of layers in the network.\n",
    "\n",
    "### The Backpropagation Algorithm ###\n",
    "#### Intuition ####\n",
    "\n",
    "In order for the network to learn, an algorithm is needed to update the weights of the neurons such that the output of the network gets closer to the desired one. \n",
    "\n",
    "In supervised learning, each input $\\mathbf{x}^0$ is paired with an output $\\mathbf{y}^*$. In a classification problem, $\\mathbf{y}^*$ will be a one-hot vector with the bit that represents the class of the input set to $1$. You can read more about one-hot vectors [here](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "The loss function or cost function $\\mathcal{L}(\\mathbf{y}^N, \\mathbf{y}^*)$ is a function that computes the distance between the current output of the network and the desired one. The gradient descent method relies on calculating the derivative of the loss function with respect to the weights of the network. \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}^l} &= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}^{l+1}} \\frac{\\partial \\mathbf{y}^{l+1}}{\\partial \\mathbf{y}^{l}} \\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^l} &= \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}^l} \\frac{\\partial \\mathbf{y}^l}{\\partial W^l}\n",
    "\\end{align*}\n",
    "\n",
    "The weights can then be updated:\n",
    "\\begin{equation*}\n",
    "W^l \\leftarrow W^l - \\eta\\frac{\\partial \\mathcal{L}}{\\partial W^l}\n",
    "\\end{equation*}\n",
    "where $\\eta > 0$ is a given learning rate. You can read more about the learning rate [here](https://en.wikipedia.org/wiki/Learning_rate).\n",
    "\n",
    "#### Loss function ####\n",
    "\n",
    "The loss function needs to fulfil the following conditions:\n",
    "- it has a derivative\n",
    "- it is written as a function of the outputs of the network\n",
    "- it can be written as an average $\\mathcal{L}(Y^N, Y^*) = \\frac{1}{n} \\sum_\\mathbf{y} \\mathcal{L}(\\mathbf{y}^N, \\mathbf{y}^*) $\n",
    "\n",
    "\n",
    "The last condition exists because a network is trained, in general, with a set of samples at once, known as a batch. The aim of training the network is to achieve a loss equal to $0$ on the entire dataset, as such using the whole dataset at once to calculate the gradient would be ideal. Unfortunately, this is unfeasible on big datasets. For this reason, small batches that fit into memory are used instead. They provide a more accurate update for the weights than using one sample at a time, while not being too computationally and memory intensive. \n",
    "Splitting the dataset into multiple batches, and then iterating over all of them is known as an epoch. \n",
    "\n",
    "\n",
    "#### The algorithm ####\n",
    "\n",
    "Since calculating the gradient of the weights depends only on the output of the current and next layer, the Backpropagation algorithm calculates the updates for the entire network starting from the last layer. The current result is then used to calculate the gradients for the previous layer until the entire network is updated. The stopping criteria for the algorithm could be completing a number of epochs, achieving a certain accuracy or not producing any significant changes. The algorithm can be seen below.\n",
    "\n",
    "<div>\n",
    "<center><img src=\"https://raw.githubusercontent.com/zhuwq0/images/main/backpropagation.png\" width=\"600\" alt=\"Backpropagation\"/></center>\n",
    "</div>\n",
    "\n",
    "### Learning methods ###\n",
    "\n",
    "Online gradient descent uses one sample per iteration, which only roughly approximates aspects of the cost function. This results in a noisy gradient descent that may not find the local minimum. Deterministic gradient descent uses the entire dataset in every iteration and, given enough time, will find the true local minimum. As discussed previously, this has a high computational cost and is not usable in practice. Stochastic gradient descent (SGD) uses a batch of samples in every iteration, thus achieving a good approximation of the real gradient. This especially reduces the computational cost for high-dimensional optimization problems, in trade for a lower convergence rate.\n",
    "\n",
    "Many improvements have been proposed to SGD. In machine learning, in particular, the result of gradient descent relies too much on setting a good learning rate. Setting this parameter too high will result in the algorithm diverging, meanwhile setting it too low will make learning slow. Denoting $\\Delta\\mathcal{J}(X, W_t) = \\frac{\\partial \\mathcal{L}}{\\partial W_t}$ as the steepest gradient for input $X$ and weights $W_t$ at iteration $t$, the SGD learning rule can be written as:\n",
    "\n",
    "\\begin{equation*}\n",
    "W_{t+1} = W_t - \\eta\\Delta\\mathcal{J}(X, W_t)\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cae5c1-468c-4b04-a75a-1d64386a5558",
   "metadata": {},
   "source": [
    "## Choosing a pre-trained network ##\n",
    "We will use a pre-trained network to speed up our training time.\n",
    "We can use the command below to check all the available pre-trained networks in **PyTorch**.\n",
    "\n",
    "Not all networks have the same input size, so you need to check what input a network expects before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af955c9-cd21-4d8f-8745-d9b9962b7b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79b9a5-b4d5-4b57-92bc-a5e62ce50263",
   "metadata": {},
   "source": [
    "## AlexNet ##\n",
    "\n",
    "We will choose AlexNet as our pre-trained network. AlexNet expects an RGB image of size 227x227.\n",
    "\n",
    "We also check the name of all the layers, as we need to know the name of the last layer. We will replace this layer since it doesn't fit our case. AlexNet was trained to classify images into 1000 classes, so the output of the network is an array of size 1000. We only have two classes, so we need to modify the output layer.\n",
    "\n",
    "We take a look at the layers of the AlexNet and identify the last layer. The last layer, or the output layer, is the layer numbered as 6 in the **classifier** part of the network. It is a Linear layer, also known as a fully connected layer, and has an input of 4096 numbers and an output of 1000 numbers, corresponding to the 1000 classes. The input of this layer comes from the output of the previous layer, so it cannot be changed, but we will change the output to just 2 numbers, to correspond to the 2 classes we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9bb683-5245-41da-97d0-021d9f866066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(weights='DEFAULT') # equivalent to ``models.alexnet(weights='IMAGENET1K_V1')``\n",
    "print(model.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac9715-34fc-41c3-bacf-cdffba9f61c2",
   "metadata": {},
   "source": [
    "## Replace the last layer of the network ##\n",
    "\n",
    "Since we have two classes, *volcano_deformation* and *background_noise*, we need a layer with 2 neurons. We create a new Linear layer with the same input size of 4096, but with an output of 2. We then set our newly created layer in position 6 in the classifier.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b75413-e441-4a02-a3c2-5538837b33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the last layer in the network, which is the output layer. In this case, it is the 6-th layer inside `classifier`\n",
    "print(f'Initian output layer of the network: {model.classifier[6]}')\n",
    "in_features = model.classifier[6].in_features\n",
    "print(f'Input features of the output layer: {in_features}')\n",
    "\n",
    "# We replace the last layer and set the output size to 2 since we have 2 classes\n",
    "new_output_layer = nn.Linear(in_features=in_features, out_features=2)\n",
    "model.classifier[6] = new_output_layer\n",
    "print(f'New output layer of the network: {model.classifier[6]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e415e3-edca-4ed4-a8ba-1e0b9a4f67e4",
   "metadata": {},
   "source": [
    "## Loss function and Optimizer ##\n",
    "\n",
    "We define a loss function and an optimizer. The loss function will be Cross Entropy Loss and the optimizer will be Adam. \n",
    "\n",
    "#### Cross Entropy Loss ####\n",
    "\n",
    "Cross-entropy loss measures the performance of a classification model whose output should represent a set of probabilities. Since the output of a network is not guaranteed to be a set of numbers from the interval [0,1] whose sum is 1, the output is also normalized. You can read more about Cross Entropy Loss [here](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) and [here](https://en.wikipedia.org/wiki/Cross-entropy).\n",
    "\n",
    "#### Adam ####\n",
    "\n",
    "Adaptive Moment Estimation (Adam) is an optimizer, where running averages of both the gradients and the second moments of the gradients are used. You can read more about Adam [here](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) and [here](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3543ca-0cbb-49cf-88ed-e0550c6459a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move the model to the selected device (either GPU or CPU)\n",
    "model = \n",
    "\n",
    "# We define a loss function\n",
    "criterion = \n",
    "\n",
    "# We define an optimizer. All parameters are being optimized\n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b5099-ceec-4f33-a684-4ca0b6f1a92b",
   "metadata": {},
   "source": [
    "## Training and Testing ##\n",
    "\n",
    "For training, we get a batch of images and we run the batch through the model and get an output. We use the loss function to get a loss value.\n",
    "\n",
    "By calling *loss.backwards()*, we calculate the gradient of the loss value by using the Backpropagation algorithm. \n",
    "We can then call *optimizer.step()* to update the weights of the network and perform the gradient descent. Since the function *step()* is called on the optimizer, the selected optimizing algorithm is used to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17674b-5035-4615-8e3c-97a624d9a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimizer, epochs=25, save_path='results/', save_name='best_model_params.pt', eval_interval=1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path) \n",
    "    model_params_path = os.path.join(save_path, save_name)\n",
    "\n",
    "    torch.save(model.state_dict(), model_params_path)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'Epoch {epoch} / {epochs}')\n",
    "        print('*' * 20)\n",
    "\n",
    "        epoch_start = time.time()\n",
    "        # Training phase\n",
    "        # We need to set the model to training mode\n",
    "        model.\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_correct_preds = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch} / {epochs}\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # get output of model\n",
    "            outputs = \n",
    "\n",
    "            # calculate the loss\n",
    "            loss = \n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # update the weights\n",
    "            optimizer.\n",
    "\n",
    "            # the prediction is the class with the highest probability\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Batch stats\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct_preds += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "        # Epoch stats\n",
    "        epoch_loss = total_loss / len(train_dataloader.dataset)\n",
    "        epoch_acc = total_correct_preds / len(train_dataloader.dataset)\n",
    "\n",
    "        print(f'Training Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}')\n",
    "        \n",
    "\n",
    "        if epoch % eval_interval == 0:\n",
    "            test_loss, test_acc = predict(model, criterion)\n",
    "\n",
    "            # save the model\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                torch.save(model.state_dict(), model_params_path)\n",
    "\n",
    "        print()\n",
    "        time_elapsed = time.time() - epoch_start\n",
    "        print(f'Epoch complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best evaluation Accuracy: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load(model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f640452-cab8-4c44-a60b-a5ae48969aff",
   "metadata": {},
   "source": [
    "For testing, we don't need to calculate the gradient. In order to calculate the gradient, **PyTorch** saves all the operations performed on the data. This uses memory and is unnecessary during testing. Thus, we need to call *torch.no_grad()*. This tells the **PyTorch** library not to save the following operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6e2a7-40a1-49cb-827f-13256373b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, criterion):\n",
    "    # Testing phase\n",
    "    # We need to set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_correct_preds = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # get output of model\n",
    "            outputs =\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = \n",
    "\n",
    "            # the prediction is the class with the highest probability\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            # stats\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct_preds += torch.sum(preds == labels.data)\n",
    "            \n",
    "    test_loss = total_loss / len(test_dataloader.dataset)\n",
    "    test_acc = total_correct_preds / len(test_dataloader.dataset)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f} Accuracy: {test_acc:.4f}')\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccaab9b-0976-4059-8cb5-6f37700b95cd",
   "metadata": {},
   "source": [
    "## Running the model ##\n",
    "\n",
    "Now we can just call the training function to train the model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04f339-e2e6-426c-a558-7a65e21423de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = fit(model, criterion, optimizer, epochs=5, \n",
    "                save_path='results/', save_name='best_model_params.pt', eval_interval=1)\n",
    "\n",
    "# Evaluate the model again after training is complete\n",
    "print()\n",
    "print('Final results:')\n",
    "test_loss, test_acc = predict(model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13dadd-df91-403c-b804-e5fe0066c461",
   "metadata": {},
   "source": [
    "## Visualizing the predictions of the model ##\n",
    "\n",
    "Finally, we can visualize the predictions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a6925-d2cd-475c-834a-cc81e01ce26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lists to save the results for visualization\n",
    "num_samples = 10\n",
    "inputs = []\n",
    "labels = []\n",
    "preds = []\n",
    "\n",
    "## Predict on the test dataset and \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (input, label) in enumerate(test_dataloader):\n",
    "        if len(inputs) > num_samples // input.size(0):\n",
    "            break\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        ## Get the output of the model\n",
    "        output = \n",
    "\n",
    "        ## Get the class with the highest probability\n",
    "        pred = output.argmax(-1)\n",
    "\n",
    "        if not torch.equal(label, pred):\n",
    "            inputs.append(input)\n",
    "            labels.append(label)\n",
    "            preds.append(pred)\n",
    "\n",
    "## Concatenate the results for visualization\n",
    "inputs = torch.cat(inputs)\n",
    "labels = torch.cat(labels)\n",
    "preds = torch.cat(preds)\n",
    "\n",
    "## Plot the results\n",
    "plot_example(inputs.cpu(), preds.cpu(), show_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba4c22",
   "metadata": {},
   "source": [
    "Let's compare the predictions of the model with the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(inputs.cpu(), labels.cpu(), show_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98fa9a4",
   "metadata": {},
   "source": [
    "Question: Do you think the model is doing a good job at classifying the images? For the examples where the model is wrong, can you tell why it is wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf65f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "760657ad",
   "metadata": {},
   "source": [
    "Question: Can you think of ways to improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654bba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5e0c42-dd4c-4aa5-b0c8-e65b30cfb427",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    " <h1> CONGRATULATIONS </h1>\n",
    "</div>\n",
    "\n",
    "You finished the tutorial. If you want to see this model being run in real time, you can visit the COMET portal: https://comet.nerc.ac.uk/comet-volcano-portal/.\n",
    "\n",
    "Select a volcano you want and scroll to to bottom of the page. On top of identifying deformation in images, the model on the portal can also pinpoint the location of the deformation by showing which parts of the image have a higher probability. \n",
    "\n",
    "If you want to try your own image, you can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844df08d-1977-435f-99a3-154e9c314781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you stopped the notebook, you need to redefine the model. You can either run the code cells above that define the model\n",
    "# or uncomment the next lines\n",
    "# model = models.alexnet(weights='DEFAULT')\n",
    "# in_features = model.classifier[6].in_features\n",
    "# new_output_layer = nn.Linear(in_features=in_features, out_features=2)\n",
    "# model.classifier[6] = new_output_layer\n",
    "# model.to(device)\n",
    "\n",
    "# Uncomment the next line to load the model checkpoint\n",
    "# This only needs to be done if you closed the notebook or if you want to load a different checkpoint\n",
    "# model.load_state_dict(torch.load('results/best_model_params.pt', weights_only=True))\n",
    "\n",
    "\n",
    "# Replace this line with an image loaded by you\n",
    "image = np.random.rand(500, 500, 3)\n",
    "\n",
    "# If your image has only one channel, uncomment the next line\n",
    "# image = torch.cat([image, image, image], dim=1)\n",
    "\n",
    "# We added a resize in case your image is not the correct size\n",
    "image_transforms = transforms.Compose([\n",
    "    # Changes the input to a tensor, also brings the channels to the front, so image.shape = (3, 227, 227) after this operation\n",
    "    transforms.ToTensor(),\n",
    "    # In case the image is in another format\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    # Resize the image to the correct size\n",
    "    transforms.Resize((227, 227)),\n",
    "])\n",
    "\n",
    "# We apply the transforms to the image\n",
    "image = image_transforms(image)\n",
    "# We change the shape of the image to 1x3x227x227 because the model needs a batch of images, so we shape our image as a batch of size 1\n",
    "# Here, image.shape = (3, 227, 227)\n",
    "image = image.view(1, *image.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image = image.to(device)\n",
    "    output = model(image)\n",
    "    preds = output.argmax(dim=-1)\n",
    "    probs = output.softmax(dim=-1)\n",
    "\n",
    "# We use image[0] to select the first image in our batch of size 1 (the only image in the batch)\n",
    "plot_example(image.cpu(), preds.cpu(), show_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c11b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
