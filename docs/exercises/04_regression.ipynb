{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and the age of the universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scientific python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate data\n",
    "\n",
    "There are many examples in Earth and Planetary Science where we are interested in the dependence of one set of data on another (_bivariate data_). We have dealt with such scenarios thus far in considering the distance of the last geomagnetic reversal from the ridge crest to get spreading rate and the difference in arrival times of the $P$ and $S$ seismic waves is related to distance from the source to the receiver. \n",
    "\n",
    "Today we will be focused on methods that allow us to investigate potential associations and relationships between variables. And using a classic problem from astrophysics to do so. The inspiration for this exercise came from Lecture 16 of Lisa Tauxe's Python for Earth Science Students class and some of the material is modified from those materials (https://github.com/ltauxe/Python-for-Earth-Science-Students).\n",
    "\n",
    "### Age of the universe\n",
    "\n",
    "Today, we will focus on using the retreat velocity of galaxies and supernova as a function of their distance as our example data set. Such data underlies what has come to be known as \"Hubble's Law\" (same Hubble as for the Hubble telescope). Hubble published these results in 1929 [Hubble, E. P. (1929) Proc. Natl. Acad. Sci., 15, 168–173.]  At the time,  it was unclear whether the universe was static, expanding, or collapsing. Hubble hypothesized that if the universe were expanding, then everything in it would be moving away from us. The greater the distance between the Earth and the galaxy, the faster it must be moving.  So all that had to be done was to measure the distance and velocity of distant galaxies.  Easy-peasy - right?  \n",
    "\n",
    "To measure velocity, Hubble made use of the doppler shift. To understand how this works, recall that the pitch you hear as an ambulance approaches changes. During doppler shift, the ambulance's pitch changes from high (as it approaches) to low (as it recedes). The pitch changes  because the relative frequency of the sound waves changes. The frequency increases as the ambulance approaches, leading to a higher pitch, and then decreases as it moves away, resulting in a lower pitch.  \n",
    "\n",
    "Just in case you haven't had this life experience, let's listen to such a siren here:\n",
    "https://www.youtube.com/watch?v=imoxDcn2Sgo\n",
    "\n",
    "<img src=\"images/Doppler_Effect.png\" width=600>\n",
    "\n",
    "The same principle applies to light, but rather than hear a change in frequency, we observe a shift in the wavelength (the color) emitted by the galaxy. If a star or galaxy is moving away from us, its absorption bands are shifted towards longer wavelengths - the red end of the visible spectrum. The faster the star or galaxy travels away from the observer, the greater the shift will be to the red:\n",
    "\n",
    "<img src=\"images/dopp-redshift01.jpg\" width=300>\n",
    "\n",
    "So a star (or galaxy) moving away from us will have a red shift with the wavelength being spread out.\n",
    "\n",
    "<img src=\"images/dopp-redshift02.jpg\" width=300>\n",
    "\n",
    "_[Figures from http://www.a-levelphysicstutor.com/wav-doppler.php](http://www.a-levelphysicstutor.com/wav-doppler.php)_\n",
    "\n",
    "Hubble measured the red shift of different galaxies and converted them to velocities. He then estimated the distance to these objects, which is harder to do (and he was pretty far off). \n",
    "\n",
    "Improving such data was a major motivation of the Hubble Space Telescope. Those data and continued improvement to approaches for estimating these distances and velocities and investigating additional types of celestial objects is a major focus of ongoing research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 1a supernovae data\n",
    "\n",
    "Let's import data from Freedman et al. (2000) of the distance and retreat velocity of type 1a supernovae. These supernovae are described as follows in a review paper that Freedman wrote in 2010 (https://doi.org/10.1146/annurev-astro-082708-101829):\n",
    "\n",
    "> One of the most accurate means of measuring cosmological distances out into the Hubble flow\n",
    "utilizes the peak brightness of SNe Ia. The potential of supernovae for measuring distances was\n",
    "clear to early researchers (e.g., Baade, Minkowski, Zwicky), but it was the Hubble diagram of\n",
    "Kowal (1968) that set the modern course for this field, followed by decades of work by Sandage,\n",
    "Tammann, and collaborators (e.g., Sandage & Tammann 1982, 1990; see also the review by\n",
    "Branch 1998). Analysis by Pskovskii (1984), followed by Phillips (1993), established a correlation\n",
    "between the magnitude of a SN Ia at peak brightness and the rate at which it declines, thus\n",
    "allowing supernova luminosities to be “standardized.” This method currently probes farthest\n",
    "into the unperturbed Hubble flow, and it possesses very low intrinsic scatter:\n",
    "*Freedman and Madore (2010) who then go onto describe how using Cepheid variable stars (a type of pulsating star) has allowed for the distances to be better calibrated.*\n",
    "\n",
    "> SNe Ia result from the thermonuclear runaway explosions of stars.\n",
    "From observations alone, the presence of SNe Ia in elliptical galaxies suggests that they do not\n",
    "come from massive stars. Many details of the explosion are not yet well understood, but the\n",
    "generally accepted view is that of a carbon-oxygen, electron-degenerate, nearly-Chandrasekharmass\n",
    "white dwarf orbiting in a binary system with a close companion *Freedman and Madore (2010)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data/Freedman2000_Supernova1a.csv file\n",
    "Supernova_data = \n",
    "Supernova_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```VCMB``` column is velocity relative to the cosmic microwave background in $km \\cdot s^{-1}$ .\n",
    "\n",
    "The ```D(Mpc)``` column is the distance in Mpc which is the unit typically used for these measurements. 1 Mpc =  3.09 x $10^{19}$ km\n",
    "\n",
    "Go ahead and double-click on this cell to see how I am getting labels that have the proper superscripts.\n",
    "\n",
    "To create nice labels with superscripts, we can use latex formatting, which can also be done in a markdown cell.  For a superscript, first we need to encase the text in dollar signs and then use the ^ symbol to make the following text a superscript. If there is more than one number in the superscript, you must enclose what you want as the superscript in curly braces.\n",
    "For example, to print $10^3$, we use $10^3$ and for 'per second' ($s^{-1}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the data with Distance on the x-axis and Velocity on the y-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the slope of this line (the Hubble constant)\n",
    "\n",
    "We have distance on the x-axis inmegaparsecs and velocity on the y-axis in km/s. The slope of this line is the Hubble constant: \n",
    "\n",
    "$v = H_o d$\n",
    "\n",
    "where $v$ is velocity, $d$ is distance, and $H_o$ is the Hubble constant. \n",
    "\n",
    "This looks a lot like the equation for a line through the data ($y=mx + b$) where $m$ is the slope and $b$ is the y-intercept.  In this case, the y-intercept should be 0 or nearly so, and $m$ is $H_o$.\n",
    "\n",
    "So how do we find the slope?\n",
    "\n",
    "Here is where we can use linear regression to find the \"best fit\" line through the data. The approach is to minimize the sum of the squares of the distances (residuals) between the points and a line through them. In this illustration below, the residuals are the vertical distance between each data point and the line:\n",
    "\n",
    "<img src=\"images/Residuals_for_Linear_Regression_Fit.png\" width=400>\n",
    "\n",
    "The approach in linear regression is to find the line that minimizes the squared value of these distances all added up. \n",
    "\n",
    "<img src=\"images/RMSE1.png\" width=400>\n",
    "<img src=\"images/RMSE2.png\" width=400>\n",
    "<img src=\"images/RMSE3.png\" width=400>\n",
    "<img src=\"images/RMSE4.png\" width=400>\n",
    "\n",
    "We determine the best-fit line through this least squares approach using *scikit-learn*. \n",
    "A straight line is a first degree polynomial (*note that the function can fit higher order polynomials as well*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a line with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model to the data\n",
    "# X = Supernova_data[['D(Mpc)']].values\n",
    "# y = Supernova_data['VCMB'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the slope and intercept of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $H_o$, the slope of the best-fit line, is 67.5 (in the odd units of kilometers per second per megaparsec).  \n",
    "\n",
    "Let's plot the best fit line on our graph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model on the data\n",
    "y_pred = \n",
    "\n",
    "\n",
    "# Add the linear fit to the scatter plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this linear model for prediction\n",
    "\n",
    "What would we predict that the velocity would be for a supernova that happened to be 350 Mpc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the velocity at 350 Mpc\n",
    "y_350 = \n",
    "print('Predicted velocity at 350 Mpc:',y_350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model fit\n",
    "\n",
    "We'd also like to know who well this model fits our data (i.e. how correlated the data are). We'll use the $R^{2}$ correlation coefficient for this. $R^{2}$ is zero for uncorrelated data, and 1 for perfectly linear data (so no misfit between the model line and data). \n",
    "\n",
    "Review how to calculate $R^{2}$:\n",
    "\n",
    "$R^{2} = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "where $SS_{res}$ is the sum of the squares of the residuals and $SS_{tot}$ is the total sum of the squares of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use it, to get what is normally called the $R^2$ value, which when 1. represents perfect agreement.\n",
    "\n",
    "<img src=\"images/Correlation_examples.svg\" width=900>\n",
    "\n",
    "> Pearson correlation coefficient between several example X,Y sets. Source: https://en.wikipedia.org/wiki/Correlation_and_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R^2 value of the model; and Print the R^2 value\n",
    "ss_res =\n",
    "ss_tot =\n",
    "r2 = \n",
    "\n",
    "print('R^2:',r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad fit!  We can have confidence that there is a strong correlation between distance and velocity. The universe is expanding.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluting the fit through plotting residuals\n",
    "\n",
    "To see how well the regression performs, the data scientist must measure how far off the estimates are from the actual values. These differences are called *residuals*.\n",
    "\n",
    "<!-- $$\n",
    "\\text{residual} ~=~ \\text{observed value} ~-~ \\text{regression estimate}\n",
    "$$ -->\n",
    "\n",
    "$$ \\epsilon_i = y_i - \\hat{y}_i $$\n",
    "\n",
    "where $\\epsilon_i$ is the residual for the $i$th data point, $y_i$ is the observed value, and $\\hat{y}_i$ is the regression estimate.\n",
    "\n",
    "A residual is what's left over – the residue – after estimation. \n",
    "\n",
    "Residuals are the vertical distances of the points from the regression line. There is one residual for each point in the scatter plot. The residual is the difference between the observed value of $y$ and the fitted value of $y$, so for the point $(x, y)$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals of the model predictions\n",
    "res = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The residual plot of a good regression shows no pattern. The residuals look about the same, above and below the horizontal line at 0, across the range of the predictor variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the age of the universe\n",
    "\n",
    "To calculate the age of the universe, we can use Hubble's law:  \n",
    "\n",
    "We had $v=H_o d$ as Hubble's law and we know that distance = velocity x time, or,  $d=vt$.  So, if we divide both sides by $v$ and  we get: \n",
    "\n",
    "1=$H_o$ t. \n",
    "\n",
    "Solving for $t$ (the age of the universe), we get \n",
    "\n",
    "$t=1/H_o$ [in some weird units.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Hubble constant H0 from the model\n",
    "H0 ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes in a Hubble constant value and calculates the age of the Universe in billions of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the function to calculate the age of the universe\n",
    "def age_of_universe(Hubble_constant):\n",
    "\n",
    "    \n",
    "    return age_byr\n",
    "\n",
    "print(f\"Age of the universe (in billions of years): {age_of_universe(H0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other data sets to estimate the Hubble constant\n",
    "\n",
    "Determining the Hubble constant continues to be a major avenue of astrophysical research. In fact, Wendy Freedman's group published another study (https://arxiv.org/abs/1907.05922) that is summarized in this short video:\n",
    "\n",
    "https://www.youtube.com/watch?v=awcnVykOKZY\n",
    "\n",
    "From that paper here is a visualization of Hubble constant determinations over the past 18 years:\n",
    "\n",
    "<img src=\"images/Hubble_Constant_Time.png\" width=600>\n",
    "\n",
    "Let's look at another data set from the 2000 study to see how different data sets can lead to different answers.\n",
    "\n",
    "## Tully-Fisher Relation galaxy data\n",
    "> The total luminosity of a spiral galaxy (corrected to face-on inclination to account for extinction)\n",
    "is strongly correlated with the galaxy’s maximum (corrected to edge-on inclination) rotation\n",
    "velocity. This relation, calibrated via the Leavitt Law or TRGB, becomes a powerful means of determining\n",
    "extragalactic distances (Tully&Fisher 1977, Aaronson et al. 1986, Pierce&Tully 1988,\n",
    "Giovanelli et al. 1997). The TF relation at present is one of the most widely applied methods for\n",
    "distance measurements *Freedman and Madore (2010)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises:\n",
    "\n",
    "- Import the 'Data/Freedman2000_IBandTullyFisher.csv' file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data/Freedman2000_IBandTullyFisher.csv file\n",
    "data = \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a linear fit to determine the slope between `VCMB` and `D(Mpc)`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the implied age of the universe from these TF galaxy data alone. Reuse the function you wrote above to calculate the age of the universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = \n",
    "print(f\"Age of the universe (in billions of years): {age_of_universe(H0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going even further out into the universe\n",
    "\n",
    "Let's look at new data sets available for the classic Hubble problem.  I found one published by Betoule et al. in 2014 [http://dx.doi.org/10.1051/0004-6361/201423413](http://dx.doi.org/10.1051/0004-6361/201423413).   In this paper, data are plotted using the parameters $z$ and $\\mu$ which are related to the red shift velocity and distance.  $z$ is the fractional shift in the spectral wavelength and $\\mu$ is related to distance. \n",
    "\n",
    "Here is a plot from the Betoule et al. paper: \n",
    "\n",
    "<img src=\"images/betoule14.png\" width=600>\n",
    "\n",
    "_[Figure from Betoule et al., 2014.]  These data are type Ia supernova from different observation collaborations_  \n",
    "\n",
    "Notice that they plotted the data on a log scale. (This hides some surprising things.)\n",
    "\n",
    "It turns out that we have been looking at data that are low-z (that is relatively close and low red shift). We  need to convert $z$ and $\\mu$ to distance and velocity to compare to the results we have considered thus far.  \n",
    "\n",
    "According to [http://hyperphysics.phy-astr.gsu.edu/hbase/Astro/hubble.html](http://hyperphysics.phy-astr.gsu.edu/hbase/Astro/hubble.html)\n",
    "\n",
    "velocity $v$ (as fraction of the speed of light, $c$) is given by\n",
    "\n",
    "${v\\over c}= {{(z+1)^2-1}  \\over {(z+1)^2+1}}$\n",
    "\n",
    "where $c=3 \\times 10^8$ $m s^{-1}$.  \n",
    "\n",
    "And according to the Betoule et al. (2014) paper, $\\mu$ relates to distance in parsecs $d$ like this:  \n",
    "\n",
    "$ \\mu = 5 \\log \\frac{d}{10} $ \n",
    "\n",
    "Let's read in the data (available from this website:  http://cdsarc.u-strasbg.fr/viz-bin/qcat?J/A+A/568/A22#sRM2.2), which are averages of the data shown in the figure above,and take a peek.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data/mu_z.csv file; Hint: use the header=1 option to skip the first row\n",
    "Betoule_data = \n",
    "Betoule_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Now we can plot it the same way as the cosmologists did in the paper, using $\\mu$ and $\\log z$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the data with z on the x-axis and mu on the y-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare these new data with the previous considered data, we must do the following:  \n",
    "- Transform $z$  to velocity  \n",
    "- Transform  $\\mu$ to distance using the equations provided. \n",
    "- Truncate the new dataset which goes to much farther distances than the 'old' data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed of light in km/s\n",
    "c = 2.9979e8 / 1000 \n",
    "\n",
    "# the formula for v from z (and c)\n",
    "Betoule_data['velocity'] = c * (((Betoule_data['z']+1.)**2-1.)/((Betoule_data['z']+1.)**2+1.)) \n",
    "\n",
    "# convert mu to Gpc\n",
    "Betoule_data['distance'] = 10000*(10.**((Betoule_data['mu'])/5.))*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a scatter plot of the Betoule data and the Supernova data on the same plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data sets are similar to one another for the \"close\" objects, but we can see that a linear model doesn't work well for objects that are at greater distances.\n",
    "\n",
    "To visualize this reality, let's plot the fit to the Freedman et al. 2000 data atop this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model to the Supernova data using Supernova_data[['D(Mpc)']] as the X values and Supernova_data['VCMB'] as the y values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals of the model predictions for the Betoule data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the linear fit to the scatter plot; And create a scatter plot of the residuals\n",
    "# Hint: use plt.subplot(2,1,1) to create a 2x1 plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this fit is quite poor.\n",
    "\n",
    "Let's make a first-order polynomial fit to all the Betoule data and then plot the residual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model to the Betoule data using Betoule_data[['distance']] as the X values and Betoule_data['velocity'] as the y values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals of the model predictions for the Betoule data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the linear fit to the scatter plot and create a scatter plot of the residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of structure to the residual of this degree 1 fit. Let's try a degree 2 polynomial fit (known as quadratic):\n",
    "\n",
    "$f(x)=ax^2+bx+c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a polynomial regression model to the Betoule data using Betoule_data[['distance']] as the X values and Betoule_data['velocity'] as the y values\n",
    "# Use a polynomial degree of 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals of the model predictions for the Betoule data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the polynomial fit to the scatter plot and create a scatter plot of the residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of structure to the residuals of this degree 2 fit (and the residuals are still high). Let's try a degree 3 polynomial fit (known as cubic):\n",
    "\n",
    "$f(x)=ax^3+bx^2+cx+d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a polynomial regression model to the Betoule data using Betoule_data[['distance']] as the X values and Betoule_data['velocity'] as the y values\n",
    "# Use a polynomial degree of 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals of the model predictions for the Betoule data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the polynomial fit to the scatter plot and create a scatter plot of the residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can a degree 4 polynomial fit do better?\n",
    "\n",
    "$f(x)=ax^4+bx^3+cx^2+dx+e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a polynomial regression model to the Betoule data using Betoule_data[['distance']] as the X values and Betoule_data['velocity'] as the y values\n",
    "# Use a polynomial degree of 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals of the model predictions for the Betoule data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the polynomial fit to the scatter plot and create a scatter plot of the residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks about the same as the cubic so might as well stick with that one as a working model.\n",
    "\n",
    "That the velocity-distance relationship is not linear is taken as evidence that the expansion of the universe is accelerating. This acceleration is attributed to dark energy:\n",
    "\n",
    "> In a matter-dominated universe, the expansion velocity of the Universe slows down over\n",
    "time owing to the attractive force of gravity. However, a decade ago two independent groups (Perlmutter et al. 1999, Riess et al. 1998) found that supernovae at z ∼ 0.5 appear to be about 10%\n",
    "fainter than those observed locally, consistent instead with models in which the expansion velocity\n",
    "is increasing; that is, a universe that is accelerating in its expansion. Combined with independent\n",
    "estimates of the matter density, these results are consistent with a universe in which one-third of\n",
    "the overall density is in the form of matter (ordinary plus dark), and two-thirds is in a form having\n",
    "a large, negative pressure, termed dark energy. *Freedman and Madore (2010)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
